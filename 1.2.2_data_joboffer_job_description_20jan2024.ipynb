{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOB OFFER'S DATA (part 2: extraction of the job description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting up for web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nessesary libraries.\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables.\n",
    "job_details = []\n",
    "csv_files = ['data_jobads_rn.csv', 'data_jobads_e.csv', 'data_jobads_da.csv']\n",
    "csv_files_20jan = ['data_jobads_rn_20jan.csv', 'data_jobads_e_20jan.csv', 'data_jobads_da_20jan.csv']\n",
    "directory = r'C:\\Users\\temulenbd\\OneDrive\\Desktop\\learn\\github_repo\\cct\\capstone_project'\n",
    "df_name = ['df_rn', 'df_e', 'df_da']\n",
    "df_name_20jan = ['df_rn_20jan', 'df_e_20jan', 'df_da_20jan']\n",
    "first_date = 'January 10, 2024'\n",
    "keywords = ['REGISTERED NURSE', 'ELECTRICIAN', 'DATA ANALYST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to remove duplicate job ads.\n",
    "def remove_duplicates(csv_new, csv_old, df_new, df_old, key_word):\n",
    "    \n",
    "    # Declare global variables.\n",
    "    global directory\n",
    "    \n",
    "    df_new = pd.read_csv(csv_new, index_col=None)\n",
    "    df_old = pd.read_csv(csv_old, index_col=None)\n",
    "    \n",
    "    merged_df = pd.merge(df_new, df_old[['id']], on='id', how='left', indicator=True)\n",
    "\n",
    "    # Filter rows where the job ID is not present in both DataFrames.\n",
    "    df_new = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "    # Drop the indicator column.\n",
    "    df_new = df_new.drop('_merge', axis=1)\n",
    "    \n",
    "    # Create the file path for CSV export.\n",
    "    file_path = os.path.join(directory, csv_new)\n",
    "    \n",
    "    # Update the existing DataFrame.\n",
    "    df_new.to_csv(file_path, index=False)\n",
    "    \n",
    "    print(f'The raw data was updated successfully as {file_path}.')\n",
    "    print(f'There are {df_new.shape[0]} new job ads added since {first_date} with the keyword <{key_word}>.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to extract job details from the available hyperlinks.\n",
    "def get_job_details(csv):\n",
    "    \n",
    "    # Declare global variables.\n",
    "    global job_details\n",
    "    \n",
    "    # Set up Chrome webdriver options.\n",
    "    option=Options()\n",
    "    option.add_experimental_option('debuggerAddress', 'localhost:0820')\n",
    "    \n",
    "    # Specify the start time.\n",
    "    start = time.time()\n",
    "    \n",
    "    # Initialize Chrome driver.\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=option)\n",
    "    \n",
    "    # Access each hyperlink, retrieve information about the job, and store it in the global variable 'job_details'.\n",
    "    df_ads = pd.read_csv(csv, index_col=None)\n",
    "    total_rows = df_ads.shape[0]\n",
    "    \n",
    "    for x in range(0, total_rows):\n",
    "        link = df_ads.iat[x, 2]\n",
    "        driver.get(link)\n",
    "        sleep(randint(2, 4))\n",
    "    \n",
    "        job_page = driver.find_element(By.ID, 'jobDescriptionText')\n",
    "        job_details.append(job_page.text)\n",
    "        sleep(randint(2, 4))\n",
    "        \n",
    "    # Specify the end time.\n",
    "    end = time.time()\n",
    "    \n",
    "    # Check results.\n",
    "    print(f'Total number of extracted job ads details: {len(job_details)}.\\n')\n",
    "    print('EXAMPLE:')\n",
    "    print(job_details[randint(0, total_rows)], '\\n')\n",
    "    print(f'The extraction was completed in: {(end - start) // 60} minutes and {(end - start) % 60} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a costum function to rewrite extracted information into existing csv files.\n",
    "def df_create_export_csv(new_df, csv):\n",
    "\n",
    "    # Declare global variables.\n",
    "    global job_details\n",
    "    global directory\n",
    "    \n",
    "    # Create a new pandas Dataframe using the ads csv file.\n",
    "    new_df = pd.read_csv(csv, index_col=None)\n",
    "    new_df['job_description'] = job_details\n",
    "    \n",
    "    # Create the file path for CSV export.\n",
    "    file_path = os.path.join(directory, csv)\n",
    "    \n",
    "    # Export the DataFrame to CSV file.\n",
    "    new_df.to_csv(file_path, index=False)\n",
    "    \n",
    "    print(f\"The raw data was rewritten to existing file and successfully exported as {file_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Remove duplicates and web scraping.\n",
    "**registered nurse ads**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw data was updated successfully as C:\\Users\\temulenbd\\OneDrive\\Desktop\\learn\\github_repo\\cct\\capstone_project\\data_jobads_rn_20jan.csv.\n",
      "There are 194 new job ads added since January 10, 2024 with the keyword <REGISTERED NURSE>.\n"
     ]
    }
   ],
   "source": [
    "remove_duplicates(csv_files_20jan[0], csv_files[0], df_name_20jan[0], df_name[0], keywords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of extracted job ads details: 194.\n",
      "\n",
      "EXAMPLE:\n",
      "Description:\n",
      "Cpl Healthcare are seeking a Staff Nurse to join an excellent Ophthalmology Clinic\n",
      "Our client is seeking a Staff Nurse to join their growing team. This clinic specializes in eye surgery and procedures on an outpatient basis. Prior ophthalmology experience not required as training will be provided\n",
      "Shift Pattern: 4x10hour shifts per week\n",
      "Applicant Requirements\n",
      "NMBI Registered General Nurse\n",
      "Previous experience in an acute surgical environment desirable\n",
      "Good teamwork skills\n",
      "Willingness to learn\n",
      "Excellent clinical skills\n",
      "Excellent communication skills\n",
      "\n",
      "EMAIL: louise.omeara@cplhealthcare.com\n",
      "Ref.no.:\n",
      "JO-2307-519025\n",
      "Locations:\n",
      "Dublin\n",
      "Salary:\n",
      "€33000 - €50000\n",
      "Employment type:\n",
      "Full Time;\n",
      "Tags:\n",
      "Clinic Nurse,Day Nurse,ENT,Eye,Laser Surgery,Nurse,Nursing,Ophthalmology,Surgical\n",
      "\n",
      "EMAIL: louise.omeara@cplhealthcare.com\n",
      "Ref.no.:\n",
      "JO-2307-519025\n",
      "Locations:\n",
      "Dublin\n",
      "Salary:\n",
      "€33000 - €50000\n",
      "Employment type:\n",
      "Full Time;\n",
      "Tags:\n",
      "Clinic Nurse,Day Nurse,ENT,Eye,Laser Surgery,Nurse,Nursing,Ophthalmology,Surgical \n",
      "\n",
      "The extraction was completed in: 21.0 minutes and 15.305526971817017 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Scrape the job details.\n",
    "get_job_details(csv_files_20jan[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw data was rewritten to existing file and successfully exported as C:\\Users\\temulenbd\\OneDrive\\Desktop\\learn\\github_repo\\cct\\capstone_project\\data_jobads_rn_20jan.csv.\n"
     ]
    }
   ],
   "source": [
    "# Update the extracted data and save the changes.\n",
    "df_create_export_csv(df_name[0], csv_files_20jan[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset variable.\n",
    "job_details = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**electrician ads**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw data was updated successfully as C:\\Users\\temulenbd\\OneDrive\\Desktop\\learn\\github_repo\\cct\\capstone_project\\data_jobads_e_20jan.csv.\n",
      "There are 54 new job ads added since January 10, 2024 with the keyword <ELECTRICIAN>.\n"
     ]
    }
   ],
   "source": [
    "remove_duplicates(csv_files_20jan[1], csv_files[1], df_name_20jan[1], df_name[1], keywords[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of extracted job ads details: 54.\n",
      "\n",
      "EXAMPLE:\n",
      "Maintenance Electrician required Dublin, Salary 50k – 55k+ Bonus.\n",
      "Your new Company\n",
      "This company is part of one of the UK & Irelands largest water companies who provides water and recycling services to over 6 million customers in England. Operating for over 20 years in the Irish market they currently operate one of Europe’s largest wastewater treatment plants, at which they currently treat over 50% of Ireland’s wastewater. The are a proven leader in the provision of innovative water, wastewater, and resource recycling solutions for a range of sectors which include municipal, industrial, and commercial industries in Ireland.\n",
      "From design and engineering to construction, through to site operation and management, they have a proven track record in the provision of Lean water and wastewater solutions that increase efficiency, reduce carbon footprint, and minimize operational cost for our customers.\n",
      "Your new role\n",
      "This role enquires you to provide expertise on all electrical systems, and problem solving/fault finding of electrical systems & equipment throughout the site to secure the continuous operation of site. Some of your main duties will be:\n",
      "· Troubleshoot and repair electrical components, panels, and systems.\n",
      "· Install and maintain industrial communication systems, heavy duty electrical equipment.\n",
      "· Perform quality testing and inspections.\n",
      "· Wire up, gland, terminate pumps, motors, VSDs, circuit boards and panels, install new conduits, trays, ladder and pull new cables where necessary.\n",
      "· Recording of all activities on CMMS\n",
      "· Provide out of hours support to plant operations during plant start-up, running and shutdown activities.\n",
      "· Participate in on-call Rota.\n",
      "· Follow all health and safety rules and regulations. Keep work area clean, safe, and orderly.\n",
      "· Perform other duties as deemed necessary by the Maintenance Engineer.\n",
      "· The position of Maintenance Electrician requires flexibility and availability as demanded by the needs of a continuous plant and process. You will be part of an on-call system providing electrical cover and as a result, after-hours and weekend interaction with the plant will be a routine aspect of the job.\n",
      "· Awareness of national and industrial technical standards and regulations\n",
      "· Be a good team player and be analytically minded in linking financial performance to operational efficiency.\n",
      "· Be able to work in a very fast paced environment where priorities may change regularly.\n",
      "· Willing to perform physically demanding tasks such as climbing ladders, working at heights and/or in confined spaces.\n",
      "· Problem solving and fault finding with MV/LV AC and LC DC switchgear and distribution systems.\n",
      "· Good command of electrical drawings\n",
      "· A disciplined step-by-step systematic approach to problems\n",
      "· Fault finding under time pressure.\n",
      "What you will need to succeed\n",
      "· 5 years relevant electrical experience in a heavy industrial environment\n",
      "· Electrical National Craft Certificate essential.\n",
      "· Very strong fault diagnosis & solving experience.\n",
      "· Ability to read complex electrical drawings and P&IDs\n",
      "· Specific experience with Rockwell / Allen Bradley Control Systems and PLCs, Endress and Hauser and ABB instrumentation, Auma actuators is advantageous.\n",
      "· Knowledge and experience of ATEX zoned areas is also advantageous.\n",
      "What you will get in return\n",
      "You will get A very competitive salary. With a range of benefits some of these benefits include:\n",
      "· A salary range of 50k – 55k\n",
      "· Overtime\n",
      "· Performance related bonus of up to 5% of salary\n",
      "· on call rate of €20 per day whilst on call.\n",
      "What you need to do now\n",
      "If you're interested in this role, click 'apply now' to forward an up-to-date copy of your CV, or call us now.\n",
      "If this job isn't quite right for you but you are looking for a new position, please contact us for a confidential discussion on your career.\n",
      "Job Type: Full-time\n",
      "Salary: €50,000.00-€55,000.00 per year\n",
      "Schedule:\n",
      "8 hour shift\n",
      "Day shift\n",
      "Monday to Friday\n",
      "Overtime\n",
      "Supplemental pay types:\n",
      "Bonus pay\n",
      "Overtime pay\n",
      "Performance bonus\n",
      "Ability to commute/relocate:\n",
      "Dublin, CO. Dublin: reliably commute or plan to relocate before starting work (preferred)\n",
      "Work Location: In person \n",
      "\n",
      "The extraction was completed in: 5.0 minutes and 46.99110245704651 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Scrape the job details.\n",
    "get_job_details(csv_files_20jan[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw data was rewritten to existing file and successfully exported as C:\\Users\\temulenbd\\OneDrive\\Desktop\\learn\\github_repo\\cct\\capstone_project\\data_jobads_e_20jan.csv.\n"
     ]
    }
   ],
   "source": [
    "# Update the extracted data and save the changes.\n",
    "df_create_export_csv(df_name[1], csv_files_20jan[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset variable.\n",
    "job_details = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data analyst ads**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw data was updated successfully as C:\\Users\\temulenbd\\OneDrive\\Desktop\\learn\\github_repo\\cct\\capstone_project\\data_jobads_da_20jan.csv.\n",
      "There are 85 new job ads added since January 10, 2024 with the keyword <DATA ANALYST>.\n"
     ]
    }
   ],
   "source": [
    "remove_duplicates(csv_files_20jan[2], csv_files[2], df_name_20jan[2], df_name[2], keywords[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of extracted job ads details: 85.\n",
      "\n",
      "EXAMPLE:\n",
      "Job Title: Strategy Analyst- Fintech\n",
      "Sector: Fintech\n",
      "Location: Dublin/Hybrid\n",
      "Salary: DOE plus benefits\n",
      "\n",
      "Our Client\n",
      "\n",
      "Our client is an award-winning Fintech company headquartered in Dublin. Due to huge growth, there is a newly created Analyst opportunity within the Strategy function.\n",
      "\n",
      "Why should you apply?\n",
      "\n",
      "This is an extremely varied role working with the strategy Director on key company growth projects. This role will put you at the centre of decision making in a team responsible for driving the growth of new products in new markets (including US, Europe, and Asia). There is real scope for professional growth here, visibility of your achievements on the company’s success, and the chance to work in a collaborative and open environment.\n",
      "\n",
      "Who should apply?\n",
      "\n",
      "You will be a data-driven individual with at least 3 years’ experience within Consulting, Strategy, or Transformation, as well as:\n",
      "Professional Services, Financial Services or Tech experience beneficial\n",
      "SaaS experience beneficial\n",
      "Excellent data analysis skills\n",
      "The desire to work in Fintech\n",
      "Strong commercial acumen and problem-solving skills\n",
      "Demonstrable presentation, influencing and communication skills\n",
      "ACA/CFA qualification beneficial but not essential\n",
      "Role and Reporting Lines\n",
      "\n",
      "Reporting to the Strategy Director you will work across new market analysis, market positioning, GTM and transformation activities, more specifically:\n",
      "Analyse and create business cases for investment, contributing to revenue growth\n",
      "Develop operating models and internal transformation initiatives\n",
      "Partner with clients on strategy\n",
      "Competitor analysis\n",
      "Interested in this position?\n",
      "To apply, please submit your CV to Mark Baker who is managing this assignment via the link below or to inquire further please contact us directly on 01 529 4200. \n",
      "\n",
      "The extraction was completed in: 9.0 minutes and 7.9710893630981445 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Scrape the job details.\n",
    "get_job_details(csv_files_20jan[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw data was rewritten to existing file and successfully exported as C:\\Users\\temulenbd\\OneDrive\\Desktop\\learn\\github_repo\\cct\\capstone_project\\data_jobads_da_20jan.csv.\n"
     ]
    }
   ],
   "source": [
    "# Update the extracted data and save the changes.\n",
    "df_create_export_csv(df_name[2], csv_files_20jan[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

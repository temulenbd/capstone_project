{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOB OFFER'S DATA (part 3: merging and cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nessesary libraries.\n",
    "import pandas as pd\n",
    "import re\n",
    "from random import randint\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables.\n",
    "label_value = ['registered_nurse', 'electrician', 'data_analyst']\n",
    "csv_file_name = ['data_jobads_rn.csv', 'data_jobads_e.csv', 'data_jobads_da.csv']\n",
    "data_frame = ['df1', 'df2', 'df3']\n",
    "to_remove = ['salary', 'schedule', 'benefits', 'location', 'job type', 'office']\n",
    "date_of_download = \"January 10, 2024\"\n",
    "before_30_days = 'before December 11, 2023'\n",
    "directory = r'C:\\Users\\temulenbd\\OneDrive\\Desktop\\learn\\github_repo\\cct\\capstone_project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to import a CSV file, add a label column, and return the DataFrame.\n",
    "def import_and_label(csv, data_f, value):\n",
    "    \n",
    "    # Read the CSV file into a DataFrame.\n",
    "    data_f = pd.read_csv(csv, index_col=None)\n",
    "    \n",
    "    # Add a new column 'label' with the specified value.\n",
    "    data_f['label'] = value\n",
    "    \n",
    "    # eturn the modified DataFrame\n",
    "    return data_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1034, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>Silver Stream Healthcare Group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical nurse manager (cnm)</td>\n",
       "      <td>sj_358f1f68cde928c4</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>Hiring ongoing</td>\n",
       "      <td>Create A Better Future For Yourself !!\\nRecrui...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "1   clinical nurse manager (cnm)  sj_358f1f68cde928c4   \n",
       "\n",
       "                                                link            date  \\\n",
       "0  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...     Just posted   \n",
       "1  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  Hiring ongoing   \n",
       "\n",
       "                                     job_description             label  \n",
       "0  Silver Stream Healthcare Group offer great emp...  registered_nurse  \n",
       "1  Create A Better Future For Yourself !!\\nRecrui...  registered_nurse  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the import_and_label function for the each CSV file.\n",
    "df1 = import_and_label(csv_file_name[0], data_frame[0], label_value[0])\n",
    "df2 = import_and_label(csv_file_name[1], data_frame[1], label_value[1])\n",
    "df3 = import_and_label(csv_file_name[2], data_frame[2], label_value[2])\n",
    "\n",
    "# Concatenate the three DataFrames along the rows (axis=0) and reset the index.\n",
    "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# Check the DataFrame.\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'date' column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to replace 'Just posted' or 'Today' with 'January 10, 2024'.\n",
    "def replace_just_posted_today(date):\n",
    "    global date_of_download\n",
    "    return date_of_download if 'Just posted' in str(date) or 'Today' in str(date) else date\n",
    "\n",
    "# Define a custom function extract and replace with relevant information.\n",
    "def remove_elements_with_colon(date):\n",
    "    date = replace_just_posted_today(date)\n",
    "    \n",
    "    if date and ('day' in str(date) or 'days' in str(date)):\n",
    "        days_ago = int(re.search(r'(\\d+) (?:day|days) ago', str(date)).group(1))\n",
    "        new_date = datetime.strptime('January 10, 2024', '%B %d, %Y') - timedelta(days=days_ago)\n",
    "        return new_date.strftime('%B %d, %Y')\n",
    "    else:\n",
    "        return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before December 11, 2023    511\n",
      "unknown                      84\n",
      "January 08, 2024             71\n",
      "December 20, 2023            46\n",
      "January 05, 2024             45\n",
      "December 22, 2023            37\n",
      "January 10, 2024             30\n",
      "January 03, 2024             30\n",
      "January 09, 2024             28\n",
      "January 04, 2024             25\n",
      "January 06, 2024             18\n",
      "December 13, 2023            14\n",
      "December 19, 2023            12\n",
      "December 14, 2023            11\n",
      "December 12, 2023            10\n",
      "December 21, 2023            10\n",
      "December 23, 2023             8\n",
      "December 16, 2023             7\n",
      "December 30, 2023             6\n",
      "January 02, 2024              6\n",
      "December 15, 2023             5\n",
      "January 07, 2024              5\n",
      "December 29, 2023             3\n",
      "December 18, 2023             2\n",
      "January 01, 2024              2\n",
      "December 28, 2023             2\n",
      "December 26, 2023             2\n",
      "December 31, 2023             1\n",
      "December 11, 2023             1\n",
      "December 24, 2023             1\n",
      "December 27, 2023             1\n",
      "Name: date, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply changes.\n",
    "df['date'] = df['date'].apply(replace_just_posted_today)\n",
    "df['date'] = df['date'].replace(['not available', 'Hiring ongoing', None], 'unknown')\n",
    "df['date'] = df['date'].replace(['Posted 30+ days ago'], before_30_days)\n",
    "df['date'] = df['date'].apply(remove_elements_with_colon)\n",
    "\n",
    "# Assuming df is your DataFrame and 'date' is the column\n",
    "date_counts = df['date'].value_counts()\n",
    "\n",
    "# Print the counts for each unique value in the 'date' column\n",
    "print(date_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'job_description' column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the costum function to find and remove unnecessary or private information.\n",
    "def remove_elements_with_colon(column_value, remove_value):\n",
    "        \n",
    "    # Convert the value to lowercase.\n",
    "    column_value = column_value.lower()\n",
    "    \n",
    "    # Split each value of the column into a list using '\\n' as a separator.\n",
    "    elements = column_value.split('\\n')\n",
    "    \n",
    "    # Find the index of the element containing given value.\n",
    "    index_of_element = next((i for i, elements in enumerate(elements) if remove_value in elements and ':' in elements), None)\n",
    "    \n",
    "    # Check if the first conditions are present in the text.\n",
    "    if index_of_element is not None:\n",
    "        next_colon_index = next((j for j in range(index_of_element + 1, len(elements)) if ':' in elements[j]), None)\n",
    "        \n",
    "        # Add an extra condition to check the second conditions are present in the text.\n",
    "        if next_colon_index is not None:\n",
    "            del elements[index_of_element:next_colon_index]\n",
    "            return '\\n'.join(elements)\n",
    "        else:\n",
    "            return column_value\n",
    "        \n",
    "    else:\n",
    "        return column_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operating for over 45 years, king & moffatt building services provide complete mechanical and electrical services across all sectors of the construction industry including industrial, logistics, food, pharmaceutical, data centre, mining, healthcare, commercial, hotel & leisure, high-end residential, public, and energy.\n",
      "\n",
      "from design stage to the installation and the ongoing maintenance of their facilities, our valued and highly skilled workforce provide our clients with an efficient, reliable and best in class service.\n",
      "\n",
      "a deloitte best managed company award winner for eight years running, we pride ourselves on being a full building services solutions provider and have successfully delivered multiple large-scale projects in ireland, the uk & mainland europe.\n",
      "\n",
      "what you would do:\n",
      "\n",
      "test electrical wiring, equipment, appliances, apparatus, and fixtures, using appropriate tools and record and report on all works. sign electrical installation certs.\n",
      "diagnose malfunctioning systems, apparatus, and components, using test equipment and hand tools, to locate the cause of a breakdown.\n",
      "inspect electrical systems, equipment and components to identify hazards, defects, and the need for adjustment or repair, and to ensure compliance with codes.\n",
      "advise management on whether continued operation of equipment could be hazardous.\n",
      "test electrical systems and continuity of circuits in electrical wiring, equipment, and fixtures, using testing devices to ensure compatibility and safety of system.\n",
      "maintain current electricians license or identification card to meet governmental regulations, keeping up to date with regulations and sharing update information with colleagues.\n",
      "use a variety of tools and equipment, such as power construction equipment, measuring devices, power tools and testing equipment. ensure equipment is in date and calibrated.\n",
      "perform business management duties such as maintaining records and files, preparing reports and ordering supplies and equipment.\n",
      "work from ladders, scaffolds, and roofs carry out testing.\n",
      "comply with all ehsq policies and procedures as required.\n",
      "\n",
      "what we are looking for:\n",
      "\n",
      "qualified electrician\n",
      "outstanding communication and interpersonal abilities.\n",
      "excellent organisational skills.\n",
      "safepass/cscs/ecs\n",
      "manual handling\n",
      "colour vision test certified\n",
      "testing and certification verified course.\n",
      "\n",
      "what we can offer you:\n",
      "\n",
      "having an inclusive and flexible culture helps the business continue to grow as a strong, dynamic and innovative organisation.\n",
      "as well as being supported and encouraged to develop your career here at king and moffatt, we also offer the following:\n",
      "\n",
      "competitive salary\n",
      "professional development support\n",
      "employee assistance program\n",
      "health and wellness programs\n",
      "bike to work scheme\n",
      "---------\n",
      "clarity healthcare is recruiting for a staff nurse- cath lab for a hospital in south dublin.\n",
      "the ideal candidate will have:\n",
      "nmbi registered general nurse licence in good standing.\n",
      "bls required.\n",
      "acls desired.\n",
      "1 year cardiology/cardiac catheterisation laboratory experience preferred.\n",
      "job specific competencies and knowledge\n",
      "able to use own initiative.\n",
      "ability to work as part of the multidisciplinary team.\n",
      "effective communication skills.\n",
      "able to manage busy workload.\n",
      "committed to service.\n",
      "willing to partake in the extended role of the nurse following appropriate training.\n",
      "for further information or to make an application, contact laura at: laura.mulchrone@clarityrecruitment.ie\n",
      "is this role not for you? feel free to reach out today to discuss other nurse vacancies available.\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the column.\n",
    "for val_rem in to_remove:\n",
    "    df['job_description'] = df['job_description'].apply(lambda x: remove_elements_with_colon(x, val_rem))\n",
    "\n",
    "# Print the modified DataFrame.\n",
    "print(df.iat[randint(0, 1034), 4])\n",
    "print('---------')\n",
    "print(df.iat[randint(0, 1034), 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**summarization of 'job_description' column long values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom function to count words in a cell.\n",
    "def count_words(cell):\n",
    "    words = cell.split()\n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical nurse manager (cnm)</td>\n",
       "      <td>sj_358f1f68cde928c4</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>create a better future for yourself !!\\nrecrui...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "1   clinical nurse manager (cnm)  sj_358f1f68cde928c4   \n",
       "\n",
       "                                                link              date  \\\n",
       "0  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "1  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...           unknown   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "1  create a better future for yourself !!\\nrecrui...  registered_nurse   \n",
       "\n",
       "   word_count  \n",
       "0         556  \n",
       "1         250  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to the job_description column.\n",
    "df['word_count'] = df['job_description'].apply(lambda x: count_words(x))\n",
    "\n",
    "# Check the changes.\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The people of the State of California do enact as follows:\\n\\n\\nSECTION 1.\\nSection 13651 of the Business and Professions Code is amended to read:\\n13651.\\n(a) (1) Every service station in this state shall provide during operating hours, and make available at no cost to customers who purchase motor vehicle fuel, water, compressed air, and a gauge for measuring air pressure to the public for use in servicing any passenger vehicle, as defined in Section 465 of the Vehicle Code, or any commercial vehicle, as defined in Section 260 of the Vehicle Code, with an unladen weight of 6,000 pounds or less.\\n(2) Every service station in this state shall display, at a conspicuous place on, at, or near the dispensing apparatus at least one clearly visible sign that shall read as follows: “CALIFORNIA LAW REQUIRES THIS STATION TO PROVIDE FREE AIR AND WATER FOR AUTOMOTIVE PURPOSES TO ITS CUSTOMERS WHO PURCHASE MOTOR VEHICLE FUEL. IF YOU HAVE A COMPLAINT NOTIFY THE STATION ATTENDANT AND/OR CALL THIS TOLL-FREE TELEPHONE NUMBER: 1 (800) ___ ____.” This sign shall meet the requirements of Sections 13473 and 13474 with regard to letter size and contrast. As used in this paragraph, automotive purposes does not include the washing of vehicles.\\n(b) (1) Every service station in this state located within 660 feet of an accessible right-of-way of an interstate or primary highway, as defined in Sections 5215 and 5220, shall provide during business hours public restrooms for use by its customers. Service stations shall not charge customers separately for the use of restroom facilities.\\n(2) The public restroom shall not be temporary or portable but shall be permanent and shall include separate facilities for men and women, each with toilets and sinks suitable for use by disabled persons in accordance with Section 19955.5 of the Health and Safety Code and Title 24 of the California Code of Regulations. However, a service station not located along an interstate highway and in a rural area, as defined by Section 101 of Title 23 of the United States Code, and where the annualized average daily traffic count is 2,500 vehicles or less, is only required to provide a single restroom to be used by both men and women unless the local legislative body or, upon designation by the local legislative body, the local building official determines and finds, based upon traffic studies and local or seasonal tourist patterns, that a single restroom would be inadequate to serve the public. In that event, the single restroom exemption shall not apply. The single restroom shall contain a toilet, urinal, and sink suitable for use by disabled persons as required by the federal Americans With Disabilities Act of 1990 (42 U.S.C. Sec. 12101 et seq.) and Title 24 of the California Code of Regulations. The single restroom shall be equipped with a locking mechanism to be operated by the user of the restroom and the restroom shall be maintained in a clean and sanitary manner.\\n(3) This subdivision does not apply to service stations that are operational prior to January 1, 1990, and that would be obligated to construct permanent restroom facilities to comply with this subdivision.\\n(4) For purposes of this subdivision, “customer” means a person who purchases any product available for sale on the premises of the service station, including items not related to the repairing or servicing of a motor vehicle.\\n(c) (1) Every service station in this state shall display at a conspicuous place on, at, or near the dispensing apparatus, or at or near the point of sale, at least one clearly visible sign showing a list of applicable state and federal fuel taxes per gallon of motor vehicle fuel sold from the dispensing apparatus. The sign may display the federal excise tax rate as “up to $.184.”\\n(2) The sign described in paragraph (1) also shall display the average per-gallon cost of gasoline and diesel fuel, as annually calculated by the State Energy Resources Conservation and Development\\nCommission,\\nCommission in consultation with the Legislative Analyst’s Office,\\nacross the industry of refiners producing transportation fuels as a result of their compliance with a market-based compliance mechanism adopted by the State Air Resources Board pursuant to Section 38570 of the Health and Safety Code.\\n(d) (1) The Division of Measurement Standards of the Department of Food and Agriculture shall, no later than January 1, 2001, establish a toll-free customer complaint telephone number. The toll-free telephone number thereby established shall be printed on the sign required pursuant to paragraph (2) of subdivision (a).\\n(2) Notwithstanding any other law, employees of the Division of Measurement Standards, upon inspection, or upon notice of a complaint forwarded pursuant to this section, are empowered to investigate a complaint against a service station for lack of free air and water and issue a citation to the station, and to collect a fine of two hundred fifty dollars ($250) per valid complaint, unless the citation is challenged in court. A citation shall not be issued if the air and water equipment is in good working order upon initial inspection, or if they are repaired to the satisfaction of the inspecting entity within 10 working days of the initial inspection. In addition, no citation based on nonfunctional air and water equipment shall be issued if the service station can establish that the equipment has been the target of repeated vandalism, substantiated by three or more police reports within six months detailing the vandalism.\\nSEC. 2.\\nNo reimbursement is required by this act pursuant to Section 6 of Article XIII\\u2009B of the California Constitution because the only costs that may be incurred by a local agency or school district will be incurred because this act creates a new crime or infraction, eliminates a crime or infraction, or changes the penalty for a crime or infraction, within the meaning of Section 17556 of the Government Code, or changes the definition of a crime within the meaning of Section 6 of Article XIII\\u2009B of the California Constitution.',\n",
       " 'summary': 'Existing law requires every service station in this state to display at a conspicuous place on, at, or near the dispensing apparatus, or at or near the point of sale, at least one clearly visible sign showing a list of applicable state and federal fuel taxes per gallon of motor vehicle fuel sold from the dispensing apparatus. A violation of this provision is an infraction.\\nExisting law establishes the State Energy Resources Conservation and Development Commission in the Natural Resources Agency, and specifies the powers and duties of the commission with respect to energy resources in the state. Under existing law, various provisions regulate petroleum supply and pricing.\\nThe California Global Warming Solutions Act of 2006 designates the State Air Resources Board as the state agency charged with monitoring and regulating sources of emissions of greenhouse gases. The act authorizes the state board to include the use of market-based compliance mechanisms.\\nThis bill would require every service station to also display the average per-gallon cost of gasoline and diesel fuel, as annually calculated by the\\ncommission,\\ncommission in consultation with the Legislative Analyst’s Office,\\nacross the industry of refiners producing transportation fuels as a result of their compliance with a market-based compliance mechanism. Because a violation of this requirement would be a crime, this bill would impose a state-mandated local program.\\nThe California Constitution requires the state to reimburse local agencies and school districts for certain costs mandated by the state. Statutory provisions establish procedures for making that reimbursement.\\nThis bill would provide that no reimbursement is required by this act for a specified reason.',\n",
       " 'title': 'An act to amend Section 13651 of the Business and Professions Code, relating to service stations.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load public-free fine tuning dataset from Datasets library.\n",
    "billsum = load_dataset('billsum', split='ca_test')\n",
    "\n",
    "# Split the dataset to test and train set.\n",
    "billsum = billsum.train_test_split(test_size=0.2, seed=1)\n",
    "\n",
    "# Check the train test values.\n",
    "billsum['train'][0]\n",
    "billsum['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f52ecacd6b439bad968e9ba06cdf28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb020b244fe46b6b0f05ac8f69e80c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load t5 cokenizer to process text and summary.\n",
    "checkpoint = 't5-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataCollatorForSeq2Seq instance for sequence-to-sequence tasks.\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ROUGE evaluation metric using the `evaluate` module.\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# Define a custom function that passes predictions and labels to compute to calculate the ROUGE metric.\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ad304aeecc4315b505627de929c2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:1126: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ed04f7ecce475dabfd98f24a43e6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.829505205154419, 'eval_rouge1': 0.1232, 'eval_rouge2': 0.034, 'eval_rougeL': 0.1022, 'eval_rougeLsum': 0.1023, 'eval_gen_len': 19.0, 'eval_runtime': 357.1417, 'eval_samples_per_second': 0.694, 'eval_steps_per_second': 0.045, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f3dee4b7d341f4bd37540b1eb95550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.616389751434326, 'eval_rouge1': 0.1318, 'eval_rouge2': 0.0421, 'eval_rougeL': 0.1098, 'eval_rougeLsum': 0.1097, 'eval_gen_len': 19.0, 'eval_runtime': 351.7333, 'eval_samples_per_second': 0.705, 'eval_steps_per_second': 0.045, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0238db04aba4e1a9562d4ccb1ccb108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5532679557800293, 'eval_rouge1': 0.1344, 'eval_rouge2': 0.0464, 'eval_rougeL': 0.1111, 'eval_rougeLsum': 0.1111, 'eval_gen_len': 19.0, 'eval_runtime': 358.1858, 'eval_samples_per_second': 0.692, 'eval_steps_per_second': 0.045, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2886ce8e848f41328220a1c45e730c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5373153686523438, 'eval_rouge1': 0.1372, 'eval_rouge2': 0.048, 'eval_rougeL': 0.1134, 'eval_rougeLsum': 0.1133, 'eval_gen_len': 19.0, 'eval_runtime': 353.4876, 'eval_samples_per_second': 0.702, 'eval_steps_per_second': 0.045, 'epoch': 4.0}\n",
      "{'train_runtime': 9038.7018, 'train_samples_per_second': 0.438, 'train_steps_per_second': 0.027, 'train_loss': 3.0181601739698842, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=248, training_loss=3.0181601739698842, metrics={'train_runtime': 9038.7018, 'train_samples_per_second': 0.438, 'train_steps_per_second': 0.027, 'train_loss': 3.0181601739698842, 'epoch': 4.0})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./Seq2SeqTraining\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('fine_tuned_t5_model_by_temuulen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:1126: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf59201735ba483b919a10228eb1f50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: {'eval_loss': 2.5373153686523438, 'eval_rouge1': 0.1372, 'eval_rouge2': 0.048, 'eval_rougeL': 0.1134, 'eval_rougeLsum': 0.1133, 'eval_gen_len': 19.0, 'eval_runtime': 359.2004, 'eval_samples_per_second': 0.69, 'eval_steps_per_second': 0.045, 'epoch': 4.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = results\n",
    "print(\"Metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.iat[532, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"we’re looking for a registered nurse for a nursing home to care for our patients with compassion and one who can facilitate their speedy recovery. the candidate will be responsible for educating them and their families on prevention methods and healthy habits. ideally, the candidate should be a responsible, gentle and well-trained professional who can provide exceptional nursing care with minimal supervision whilst following health and safety guidelines faithfully and consistently. the goal is to promote the patient's well-being by providing high quality nursing care.\\nmonitor patient’s condition and assess their needs to provide the best possible care.\\nobserve and interpret patient’s symptoms and communicate them to physicians.\\ncollaborate with physicians and nurses to devise individualized care plans for patients.\\nperform routine procedures (blood pressure measurements, administering injections etc.) and fill in patient’s charts.\\nadjust and administer patient’s medication(s) and provide treatments according to the physician’s orders.\\ninspect the facilities and act to maintain excellent hygiene and safety (decontaminating equipment, sanitizing surfaces, preparing beds etc.).\\nprovide instant medical care in emergencies.\\nassist surgeons during operations.\\nsupervise and train lpns and nursing assistants.\\nfoster a supportive and compassionate environment to care for patients and their families.\\nexpand their knowledge and capabilities by attending educational workshops, conferences etc.\\nrequirements\\nrequirements:\\nregistered with the nmbi (nursing and midwifery board of ireland)\\nat least 6 months-1 year post-registration experience in elderly care.\\nexcellent communication and interpersonal skills.\\nstamp 4 or valid irish work permit (eligible to work in ireland)\\nproven experience as a registered nurse.\\nexcellent knowledge of nursing care methods and procedures.\\nexcellent knowledge of emergency care.\\nin-depth knowledge of health and safety guidelines and procedures (sanitation, decontamination etc.) and willingness to follow them at all times.\\na team player with excellent communication and interpersonal skills.\\nresponsible and compassionate.\\noutstanding organizational and multi-tasking skills.\\npatient with excellent problem-solving skills.\\nexperience:\\nhome health: 1 year (required)\\neducation:\\nbachelor's (required)\\nlicence:\\nnursing and midwifery board of ireland registration (required)\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 500, but your input_length is only 320. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=160)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttm healthcare are currently recruiting a clinical nurse manager 2 theatre on behalf of an east dublin based hospital . the role is responsible for the provision of a quality service in line with standards of theatre nursing practice . as a key member of the senior management team, the position requires a strategic approach to the development of services and structures, embracing continuous quality improvement and the management of changes necessary to achieve organisational objectives. be registered in the general division of the register of nurses maintained by nmbi have at least five years nursing experience in the cnm2 in theatre, a full time permanent role working 37.5 hours a week . this is a . a health care . staff and staff in an east . dublin's a staff member, the role will demonstrate managerial and leadership skills and facilitate effective communication with colleagues in the hospital, the . ‘the . it requires . be a. the position . to be registered . in a ‘continued .. the a number of . at least 5 years recent relevant post-registration nursing . and a minimum of three years have at . an . main . services and ., . of the nm2, the hospital’s . that a good . post-skilled. . for a long . long-term . working . with a prior . or . have a position in an e. the ‘skill . on a total .’. the job,’ . work in the register. the full-time . (full-time or equivalent post-election. – . people’s nursing.. be in pursuit of the same . they have at minimum five years. the nursing experience, e .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"fine_tuned_t5_model_by_temuulen\")\n",
    "\n",
    "summary = summarizer(text, max_length=500, min_length=400, length_penalty=2.0, num_beams=4)[0]['summary_text']\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 500, but your input_length is only 320. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=160)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttm healthcare are currently recruiting a clinical nurse manager 2 theatre . role is responsible for the provision of a quality service in line with standards of theatre nursing practice . position requires a strategic approach to the development of services and structures . be registered in the general division of the register of nurses maintained by nmbi have at least five years relevant post-registration nursing experience (full-time or equivalent hours part-time) in an acute hospital setting . minimum of three years nursing experience in peri-operative theatre nursing.com . tp a nurse manager for a . the cnm 2 theatre working 37.5 hours a week and a key member of the senior management and the role will demonstrate managerial and leadership skills and the management of the . and the 'the management of nm2 in theatre (nmbi . of the main . nursing . in a post . or in n - post a recognised post- ni . post nbc . experience in an ad . have a nursing a minimum of 'full i . on a regular basis ap . time a hospital . work t a, nursing ns 'n t, . working a full a. 'd n' or a new n in the n, nursing and n’s nursing , the tm neo d, post grad course in 'ad and the staff . staff 'work . but a working 's as t. n2 in i' and ., nt n service in , 'de n the hospital ' ac nn n services .\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
    "\n",
    "summary = summarizer(text, max_length=500, min_length=400, length_penalty=2.0, num_beams=4)[0]['summary_text']\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix:\n",
      "[[1.         0.49612862 0.4358911 ]\n",
      " [0.49612862 1.         0.29630706]\n",
      " [0.4358911  0.29630706 1.        ]]\n",
      "\n",
      "Cosine Similarity Matrix (Normalized):\n",
      "[[1.         0.49612862 0.4358911 ]\n",
      " [0.49612862 1.         0.29630706]\n",
      " [0.4358911  0.29630706 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Example tokenized texts as strings\n",
    "text1 = \"ttm healthcare are currently recruiting a clinical nurse manager 2 theatre on behalf of an east dublin based hospital.\\nthis is a full time permanent role working 37.5 hours per week.\\n\\nthe role:\\nthe role is responsible for the provision of a quality service in line with standards of theatre nursing practice. as a key member of the senior management team, the cnm2 in theatre (general) will demonstrate managerial and leadership skills and facilitate effective communication with colleagues in the hospital. the position requires a strategic approach to the development of services and structures, embracing continuous quality improvement and the management of changes necessary to achieve organisational objectives.\\n\\nessential criteria:\\nbe registered in the general division of the register of nurses maintained by nmbi\\nhave at least five years recent relevant post-registration nursing experience (full-time or equivalent hours part-time) in an acute hospital setting and a minimum of three years nursing experience in peri-operative theatre nursing\\nhave a recognised post-registration nursing course - higher diploma or post grad course, in peri-operative theatre nursing or equivalent or be in pursuit of same\\n\\nbenefits:\\ncompetitive salary\\nup to 5% pension contribution\\nsick pay\\nmaternity benefit\\nfree parking\\nan education support programme\\ndevelopment opportunities\\nopportunities for career progression\\nsubsidised restaurant\\nemployee assistance programme\\nlife assurance\\nfree parking\\n\\na full job description is available upon request.\\nfor more information call louise on 015136740 or click apply with your most recent cv today\\n\\nttm healthcare solutions is an equal opportunities employer\"\n",
    "text2 = \"person specification: qualifications:\\nactive nmbi pin\\npostgraduate qualification in cardiology/cardiovascular nursing preferred.\\nadvanced health assessment desirable.\\n\\nrequired experience & skills:\\nadvanced cardiovascular life support certification.\\n3-5 years of cardiology nursing in the acute setting within the past 5-7 years.\\nleadership experience required.\\nproficient in speaking, reading, and writing grammatically correct english.\\neffective time management skills.\\n\\nbenefits of working with three q:\\nassistance with improving your cv.\\ninterview preparation support.\\na €250 referral campaign for recommending qualified candidates in the healthcare industry.\\na €250 training bursary to support your professional development.\\nafter-placement support ensures your continued success in the healthcare field.\"\n",
    "text3 = \"we’re looking for a registered nurse for a nursing home to care for our patients with compassion and one who can facilitate their speedy recovery. the candidate will be responsible for educating them and their families on prevention methods and healthy habits. ideally, the candidate should be a responsible, gentle and well-trained professional who can provide exceptional nursing care with minimal supervision whilst following health and safety guidelines faithfully and consistently. the goal is to promote the patient's well-being by providing high quality nursing care.\\nmonitor patient’s condition and assess their needs to provide the best possible care.\\nobserve and interpret patient’s symptoms and communicate them to physicians.\\ncollaborate with physicians and nurses to devise individualized care plans for patients.\\nperform routine procedures (blood pressure measurements, administering injections etc.) and fill in patient’s charts.\\nadjust and administer patient’s medication(s) and provide treatments according to the physician’s orders.\\ninspect the facilities and act to maintain excellent hygiene and safety (decontaminating equipment, sanitizing surfaces, preparing beds etc.).\\nprovide instant medical care in emergencies.\\nassist surgeons during operations.\\nsupervise and train lpns and nursing assistants.\\nfoster a supportive and compassionate environment to care for patients and their families.\\nexpand their knowledge and capabilities by attending educational workshops, conferences etc.\\nrequirements\\nrequirements:\\nregistered with the nmbi (nursing and midwifery board of ireland)\\nat least 6 months-1 year post-registration experience in elderly care.\\nexcellent communication and interpersonal skills.\\nstamp 4 or valid irish work permit (eligible to work in ireland)\\nproven experience as a registered nurse.\\nexcellent knowledge of nursing care methods and procedures.\\nexcellent knowledge of emergency care.\\nin-depth knowledge of health and safety guidelines and procedures (sanitation, decontamination etc.) and willingness to follow them at all times.\\na team player with excellent communication and interpersonal skills.\\nresponsible and compassionate.\\noutstanding organizational and multi-tasking skills.\\npatient with excellent problem-solving skills.\\nexperience:\\nhome health: 1 year (required)\\neducation:\\nbachelor's (required)\\nlicence:\\nnursing and midwifery board of ireland registration (required)\"\n",
    "\n",
    "# Create CountVectorizer and fit-transform the texts\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform([text1, text2, text3])\n",
    "\n",
    "# Compute cosine similarity between the vectors\n",
    "cosine_sim = cosine_similarity(X)\n",
    "\n",
    "# Normalize the vectors before computing cosine similarity\n",
    "normalized_X = normalize(X, norm='l2', axis=1)\n",
    "cosine_sim_normalized = cosine_similarity(normalized_X)\n",
    "\n",
    "print(\"Cosine Similarity Matrix:\")\n",
    "print(cosine_sim)\n",
    "print(\"\\nCosine Similarity Matrix (Normalized):\")\n",
    "print(cosine_sim_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-ai-textanalytics==5.3.0\n",
      "  Downloading azure_ai_textanalytics-5.3.0-py3-none-any.whl.metadata (82 kB)\n",
      "     ---------------------------------------- 0.0/82.8 kB ? eta -:--:--\n",
      "     -------------- ------------------------- 30.7/82.8 kB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------- --------- 61.4/82.8 kB 656.4 kB/s eta 0:00:01\n",
      "     -------------------------------------- 82.8/82.8 kB 771.4 kB/s eta 0:00:00\n",
      "Collecting azure-core<2.0.0,>=1.24.0 (from azure-ai-textanalytics==5.3.0)\n",
      "  Downloading azure_core-1.29.7-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting azure-common~=1.1 (from azure-ai-textanalytics==5.3.0)\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting isodate<1.0.0,>=0.6.1 (from azure-ai-textanalytics==5.3.0)\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 0.0/41.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.7/41.7 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\temulenbd\\anaconda3\\lib\\site-packages (from azure-ai-textanalytics==5.3.0) (4.7.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\temulenbd\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.3.0) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\temulenbd\\anaconda3\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.3.0) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\temulenbd\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.3.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\temulenbd\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.3.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\temulenbd\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.3.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\temulenbd\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.3.0) (2023.7.22)\n",
      "Downloading azure_ai_textanalytics-5.3.0-py3-none-any.whl (298 kB)\n",
      "   ---------------------------------------- 0.0/298.6 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 71.7/298.6 kB 1.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 153.6/298.6 kB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 276.5/298.6 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 298.6/298.6 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading azure_core-1.29.7-py3-none-any.whl (192 kB)\n",
      "   ---------------------------------------- 0.0/192.9 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 112.6/192.9 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 192.9/192.9 kB 2.9 MB/s eta 0:00:00\n",
      "Installing collected packages: azure-common, isodate, azure-core, azure-ai-textanalytics\n",
      "Successfully installed azure-ai-textanalytics-5.3.0 azure-common-1.1.28 azure-core-1.29.7 isodate-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-ai-textanalytics==5.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = '26b9cb9a3b884f789b1a98d4f0d79b60'\n",
    "endpoint = 'https://temulenbd.cognitiveservices.azure.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2573901743.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[82], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    set LANGUAGE_KEY '26b9cb9a3b884f789b1a98d4f0d79b60'\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "set LANGUAGE_KEY '26b9cb9a3b884f789b1a98d4f0d79b60'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                \n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b052af545d4aaba17be2cd7b85a867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\temulenbd\\.cache\\huggingface\\hub\\models--t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c12b7ca674648189a1339afdf82c49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdb47c2bd4f42bb8fe6e26aee2484d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1573: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3103f7d4e3db4f0d9d0c96bc5b01f238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca56de7a68f49b0bb785fcaa675dad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')                        \n",
    "model = AutoModelWithLMHead.from_pretrained('t5-base', return_dict=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummarize: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m text,\n\u001b[0;32m      2\u001b[0m                           return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m                           truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"summarize: \" + text,\n",
    "                          return_tensors='pt',\n",
    "                          truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids = model.generate(inputs, max_length=500, min_length=300, length_penalty=5., num_beams=2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'revisiting few-sample bert fine-tuning'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'REVISITING FEW-SAMPLE BERT FINE-TUNING'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw data was transformed and exported successfully as C:\\Users\\temulenbd\\OneDrive\\Desktop\\learn\\github_repo\\cct\\capstone_project\\data_jobads_final.csv.\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(directory, 'data_jobads_final.csv')\n",
    "    \n",
    "# Export the DataFrame to CSV file.\n",
    "df.to_csv(file_path, index=False)\n",
    "    \n",
    "print(f\"The raw data was transformed and exported successfully as {file_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training T5 model for text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load public-free fine tuning dataset from Datasets library.\n",
    "billsum = load_dataset('billsum', split='ca_test')\n",
    "\n",
    "# Split the dataset to test and train set.\n",
    "billsum = billsum.train_test_split(test_size=0.2, seed=1)\n",
    "\n",
    "# Check the train test values.\n",
    "billsum['train'][0]\n",
    "billsum['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load t5 cokenizer to process text and summary.\n",
    "checkpoint = 't5-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataCollatorForSeq2Seq instance for sequence-to-sequence tasks.\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ROUGE evaluation metric using the `evaluate` module.\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# Define a custom function that passes predictions and labels to compute to calculate the ROUGE metric.\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./Seq2SeqTraining\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('fine_tuned_t5_model_by_temuulen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = results\n",
    "print(\"Metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ttm healthcare are currently recruiting a clinical nurse manager 2 theatre on behalf of an east dublin based hospital.\\nthis is a full time permanent role working 37.5 hours per week.\\n\\nthe role:\\nthe role is responsible for the provision of a quality service in line with standards of theatre nursing practice. as a key member of the senior management team, the cnm2 in theatre (general) will demonstrate managerial and leadership skills and facilitate effective communication with colleagues in the hospital. the position requires a strategic approach to the development of services and structures, embracing continuous quality improvement and the management of changes necessary to achieve organisational objectives.\\n\\nessential criteria:\\nbe registered in the general division of the register of nurses maintained by nmbi\\nhave at least five years recent relevant post-registration nursing experience (full-time or equivalent hours part-time) in an acute hospital setting and a minimum of three years nursing experience in peri-operative theatre nursing\\nhave a recognised post-registration nursing course - higher diploma or post grad course, in peri-operative theatre nursing or equivalent or be in pursuit of same\\n\\nbenefits:\\ncompetitive salary\\nup to 5% pension contribution\\nsick pay\\nmaternity benefit\\nfree parking\\nan education support programme\\ndevelopment opportunities\\nopportunities for career progression\\nsubsidised restaurant\\nemployee assistance programme\\nlife assurance\\nfree parking\\n\\na full job description is available upon request.\\nfor more information call louise on 015136740 or click apply with your most recent cv today\\n\\nttm healthcare solutions is an equal opportunities employer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"fine_tuned_t5_model_by_temuulen\")\n",
    "\n",
    "summary = summarizer(text, max_length=500, min_length=400, length_penalty=2.0, num_beams=4)[0]['summary_text']\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
    "\n",
    "summary = summarizer(text, max_length=500, min_length=400, length_penalty=2.0, num_beams=4)[0]['summary_text']\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

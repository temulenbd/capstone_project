{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART III: CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. GENERAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **load module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nessesary libraries.\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import nltk\n",
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "import gpustat\n",
    "import platform\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "from scipy.sparse import hstack\n",
    "from transformers import Trainer\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from transformers import BertForSequenceClassification\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **check computational environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOWS VERSION: Windows-10-10.0.22631-SP0\n",
      "PYTHON VERSION: 3.11.4 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 13:38:37) [MSC v.1916 64 bit (AMD64)]\n",
      "CPU CORE: 4\n",
      "CPU SPEED: scpufreq(current=2496.0, min=0.0, max=2496.0)\n",
      "GPU: NVIDIA GeForce GTX 1650\n",
      "RAM: 31.87 GB\n",
      "HARD DRIVE: 237.45 GB\n"
     ]
    }
   ],
   "source": [
    "# List the software and hardware configurations used for conducting the experiment.\n",
    "print('WINDOWS VERSION:', platform.platform())\n",
    "print('PYTHON VERSION:', sys.version)\n",
    "print('CPU CORE:', psutil.cpu_count(logical=False))\n",
    "print('CPU SPEED:', psutil.cpu_freq())\n",
    "print('GPU:', gpustat.new_query().gpus[0].name)\n",
    "print(f'RAM: {psutil.virtual_memory().total/(1024 ** 3):.2f} GB')\n",
    "print(f\"HARD DRIVE: {psutil.disk_usage('/').total/(1024 ** 3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **load dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*experiment dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the experiment dataset is: (1166, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     job_description             label\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse\n",
       "1  create a better future for yourself  recruitne...  registered_nurse"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset as pandas data frame.\n",
    "df_experiment = pd.read_csv('data_jobads_final.csv', index_col=None)\n",
    "\n",
    "# Apply small modifications.\n",
    "df_experiment['job_description'] = df_experiment['job_description'].str.replace('\\n', ' ')\n",
    "df_experiment = df_experiment.dropna().reset_index(drop=True)\n",
    "df_experiment = df_experiment.iloc[:,-2:]\n",
    "\n",
    "print('The shape of the experiment dataset is:', df_experiment.shape)\n",
    "df_experiment.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*benchmark dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets as pandas data frame.\n",
    "df_benchmark_train = pd.read_csv('ag_news_train.csv', index_col=None)\n",
    "df_benchmark_test = pd.read_csv('ag_news_test.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the train dataset for benchmark is: (120000, 2)\n",
      "The shape of the test dataset for benchmark is: (7600, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reut...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Re...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0   Wall St. Bears Claw Back Into the Black (Reut...  business\n",
       "1   Carlyle Looks Toward Commercial Aerospace (Re...  business"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The shape of the train dataset for benchmark is:', df_benchmark_train.shape)\n",
    "print('The shape of the test dataset for benchmark is:', df_benchmark_test.shape)\n",
    "df_benchmark_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CLASSIFICATION WITH FINE-TUNED BERT MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the timer to track the execution duration.\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*load dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     job_description             label\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse\n",
       "1  create a better future for yourself  recruitne...  registered_nurse"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the original DataFrame for experimentation with BERT.\n",
    "df_bert = df_experiment.copy()\n",
    "\n",
    "df_bert.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*preprocess dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'registered_nurse', 1: 'electrician', 2: 'data_analyst'}\n",
      "{'registered_nurse': 0, 'electrician': 1, 'data_analyst': 2}\n"
     ]
    }
   ],
   "source": [
    "# Create 'id2label', 'label2id' variables for mapping the labels.\n",
    "labels = df_experiment['label'].unique().tolist()\n",
    "num_labels = len(labels)\n",
    "id2label = {id:label for id, label in enumerate(labels)}\n",
    "label2id = {label: id for id, label in enumerate(labels)}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     job_description             label  \\\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "1  create a better future for yourself  recruitne...  registered_nurse   \n",
       "\n",
       "   label_encoded  \n",
       "0              0  \n",
       "1              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the 'label' column.\n",
    "df_experiment['label_encoded'] = df_experiment.label.map(lambda x: label2id[x.strip()])\n",
    "\n",
    "df_experiment.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE PROPORTION OF TOTAL LABEL ID:\n",
      "0    0.552316\n",
      "1    0.125214\n",
      "2    0.322470\n",
      "Name: label_encoded, dtype: float64 \n",
      "\n",
      "THE COUNT OF TOTAL LABEL ID:\n",
      "0    644\n",
      "2    376\n",
      "1    146\n",
      "Name: label_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine the distribution and value counts for the 'label_encoded' column.\n",
    "print('the proportion of total label ID:'.upper())\n",
    "print(df_experiment['label_encoded'].value_counts(normalize=True).sort_index(), '\\n')\n",
    "\n",
    "print('the count of total label ID:'.upper())\n",
    "print(df_experiment['label_encoded'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialize the gpu* (optional)\n",
    "\n",
    "To enhance the effectiveness of managing matrix and tensor operations, the CUDA device was created. This capability represents a key advantage of utilizing the BERT model within the Torch framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA was successfully installed and compiled on my device.\n",
      "CUDA device name is: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Check whether CUDA is accessible and, if so, create a CUDA device.\n",
    "cuda_available = torch.cuda.is_available()\n",
    "cuda_device= torch.cuda.get_device_name(0)\n",
    "\n",
    "if cuda_available == True:\n",
    "    device = torch.device('cuda')\n",
    "    print('CUDA was successfully installed and compiled on my device.')\n",
    "    print('CUDA device name is:', cuda_device)\n",
    "else:\n",
    "    print('Cuda in not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*train test split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_tokens(tokens_list, model):\n",
    "    vectors = [model[word] for word in tokens_list if word in model]\n",
    "    if vectors:\n",
    "        # Averaging the vectors (You could choose another aggregation method)\n",
    "        embedding = np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        # Use a zero vector if none of the tokens were found in the Word2Vec model\n",
    "        embedding = np.zeros(model.vector_size)\n",
    "        \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL shape: (1166, 3)\n",
      "TRAINING shape: (734, 3)\n",
      "VALIDATION shape: (82, 3)\n",
      "TEST shape: (350, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split the DataFrame into training and testing sets and maintain label proportions.\n",
    "validation_train, test = train_test_split(df_experiment, test_size=0.3, random_state=630, stratify=df_experiment['label'])\n",
    "train, validation = train_test_split(validation_train, test_size=0.1, random_state=630, stratify=validation_train['label'])\n",
    "\n",
    "print('TOTAL shape:', df_experiment.shape)\n",
    "print('TRAINING shape:', train.shape)\n",
    "print('VALIDATION shape:', validation.shape)\n",
    "print('TEST shape:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*convert to Dataset format*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each set to Dataset format.\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "val_dataset = Dataset.from_pandas(validation)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "\n",
    "# Remove '__index_level_0__' feature.\n",
    "train_dataset = train_dataset.remove_columns('__index_level_0__')\n",
    "val_dataset = val_dataset.remove_columns('__index_level_0__')\n",
    "test_dataset = test_dataset.remove_columns('__index_level_0__')\n",
    "\n",
    "# Create DatasetDict variable.\n",
    "jobads = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test' : test_dataset\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialize model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a tokenizer from the 'bert-base-uncased' pretrained model.\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Initialize a BERT-based sequence classification model.\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
    "                                                      num_labels=3,\n",
    "                                                      id2label=id2label,\n",
    "                                                      label2id=label2id)\n",
    "# Move the model to device.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*tokenize text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom tokenization function for processing long and short texts.\n",
    "def custom_tokenize(batch, strategy='default', max_length=512):\n",
    "    \n",
    "    tokenized_outputs = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "    for text in batch['job_description']:\n",
    "        # Tokenize using the default strategy if the text is shorter than the maximum length.\n",
    "        if strategy == 'default':\n",
    "            inputs = tokenizer.encode_plus(text, max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
    "        # Tokenize using the default strategy if the text is longer than the maximum length.\n",
    "        elif strategy == 'head-tail':\n",
    "            tokens = tokenizer.tokenize(text)\n",
    "\n",
    "            head_length = int((max_length - 3) * 0.6)\n",
    "            tail_length = (max_length - 3) - head_length\n",
    "            # If the text is longer than the specified maximum length, split it into head and tail parts.\n",
    "            if len(tokens) > max_length - 2:\n",
    "                head_tokens = tokens[:head_length]\n",
    "                tail_tokens = tokens[-tail_length:]\n",
    "                input_ids = tokenizer.encode_plus(text=' '.join(head_tokens + tail_tokens), max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')['input_ids']\n",
    "                attention_mask = tokenizer.encode_plus(text=' '.join(head_tokens + tail_tokens), max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')['attention_mask']\n",
    "            # If the text is within the maximum length, tokenize it as is.\n",
    "            else:\n",
    "                encoded_plus = tokenizer.encode_plus(text, max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
    "                input_ids, attention_mask = encoded_plus['input_ids'], encoded_plus['attention_mask']\n",
    "            inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "        else:\n",
    "\n",
    "            pass\n",
    "\n",
    "        # Append tokenized input and attention mask to the outputs.\n",
    "        tokenized_outputs['input_ids'].append(inputs['input_ids'].squeeze().tolist())\n",
    "        tokenized_outputs['attention_mask'].append(inputs['attention_mask'].squeeze().tolist())\n",
    "\n",
    "    return tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a costum function for tokenization using the 'head-tail' strategy.\n",
    "def tokenize(examples):\n",
    "    return custom_tokenize(examples, strategy='head-tail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2846d0d146742aa85f72c9631df33e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/734 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1220 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8062e6356c4f4c9c8e33e04877fa76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/82 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed37e2e24f94b53b6bf406dcdb70e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['job_description', 'label', 'label_encoded', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 734\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['job_description', 'label', 'label_encoded', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 82\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['job_description', 'label', 'label_encoded', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 350\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the dataset.\n",
    "jobads_encoded = jobads.map(tokenize, batched=True, batch_size=None)\n",
    "\n",
    "print(jobads_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dataset format to PyTorch tensors.\n",
    "jobads_encoded.set_format('torch', columns=['input_ids', 'attention_mask', 'label_encoded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*manage the loss function for inbalanced text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6594, 1.0367, 0.6026])\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights.\n",
    "labels = train['label_encoded'].unique()\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=labels,\n",
    "                                     y=train['label_encoded'])\n",
    "\n",
    "# Convert the computed class weights to a PyTorch tensor.\n",
    "class_weights = torch.from_numpy(class_weights).float()\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['job_description', 'label', 'labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 734\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['job_description', 'label', 'labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 82\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['job_description', 'label', 'labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 350\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Finalise the dataset.\n",
    "jobads_encoded = jobads_encoded.rename_column('label_encoded', 'labels')\n",
    "\n",
    "print(jobads_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom trainer class.\n",
    "class WeightedLossTrainer(Trainer):\n",
    "    \n",
    "    # Override the method for loss computation.\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        labels = inputs.get('labels')\n",
    "        \n",
    "        # Move class weights to device.\n",
    "        class_weights_device = class_weights.to(model.device)\n",
    "        \n",
    "        # Calculate the loss using CrossEntropyLoss function with the computed class weights.\n",
    "        loss_func = nn.CrossEntropyLoss(weight=class_weights_device)\n",
    "        loss = loss_func(logits, labels)\n",
    "        \n",
    "        # Return a tuple containing loss and outputs if 'return_outputs' is True.\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*manage training argumets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a costum function to compute accuracy, F1, precision, and recall for a given set of predictions.\n",
    "def compute_metrics(pred):\n",
    "  \n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  \n",
    "  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  \n",
    "  return {'Accuracy': acc,\n",
    "          'F1': f1,\n",
    "          'Precision': precision,\n",
    "          'Recall': recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size for training.\n",
    "batch_size = 16\n",
    "\n",
    "# Calculate the number of logging steps based on the dataset size and batch size.\n",
    "logging_steps = len(jobads_encoded['train']) // batch_size\n",
    "\n",
    "# Specify the directory where the trained model and logs will be saved.\n",
    "output_dir = 'ft_bert_temuulen'\n",
    "\n",
    "# Create an instance of TrainingArguments to configure the training process.\n",
    "training_args = TrainingArguments(output_dir=output_dir,\n",
    "                                  num_train_epochs=3,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  per_gpu_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  save_strategy='epoch',\n",
    "                                  fp16=True,\n",
    "                                  load_best_model_at_end=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*fine-tune the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the WeightedLossTrainer for training the model.\n",
    "trainer = WeightedLossTrainer(model=model,\n",
    "                              args=training_args,\n",
    "                              train_dataset=jobads_encoded['train'],\n",
    "                              eval_dataset=jobads_encoded['validation'],\n",
    "                              tokenizer=tokenizer,\n",
    "                              compute_metrics= compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39728a914594a978b02c7e171b25d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/276 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4924, 'learning_rate': 1.673913043478261e-05, 'epoch': 0.49}\n",
      "{'loss': 0.0707, 'learning_rate': 1.3478260869565218e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e9d73a1c30472b894506eab8349903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018695557489991188, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 29.7728, 'eval_samples_per_second': 2.754, 'eval_steps_per_second': 0.202, 'epoch': 1.0}\n",
      "{'loss': 0.01, 'learning_rate': 1.0217391304347829e-05, 'epoch': 1.47}\n",
      "{'loss': 0.0237, 'learning_rate': 7.028985507246377e-06, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4e2a64464d4d7497f40ec2c6d36b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.003752512624487281, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 30.0971, 'eval_samples_per_second': 2.725, 'eval_steps_per_second': 0.199, 'epoch': 2.0}\n",
      "{'loss': 0.02, 'learning_rate': 3.768115942028986e-06, 'epoch': 2.45}\n",
      "{'loss': 0.0041, 'learning_rate': 5.072463768115942e-07, 'epoch': 2.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695b0752a43f4bd7a74f391dd5130307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.003047032281756401, 'eval_Accuracy': 1.0, 'eval_F1': 1.0, 'eval_Precision': 1.0, 'eval_Recall': 1.0, 'eval_runtime': 28.8592, 'eval_samples_per_second': 2.841, 'eval_steps_per_second': 0.208, 'epoch': 3.0}\n",
      "{'train_runtime': 2534.305, 'train_samples_per_second': 0.869, 'train_steps_per_second': 0.109, 'train_loss': 0.10129850775516336, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=276, training_loss=0.10129850775516336, metrics={'train_runtime': 2534.305, 'train_samples_per_second': 0.869, 'train_steps_per_second': 0.109, 'train_loss': 0.10129850775516336, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the training.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*save model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned BERT model.\n",
    "trainer.model.save_pretrained('ft_bert_temuulen2')\n",
    "\n",
    "# Save the tokenizer used for fine-tuning to the 'ft_bert_temuulen3_tokenizer'.\n",
    "tokenizer.save_pretrained('ft_bert_temuulen_tokenizer2')\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*evaluate model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory paths for the fine-tuned model and tokenizer.\n",
    "model_path = 'ft_bert_temuulen2'\n",
    "tokenizer_path = 'ft_bert_temuulen_tokenizer2'\n",
    "\n",
    "# Load the BERT and the tokenizer.\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcc9c9efa9440be88a9dd7e5c7cabc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load prepared an unseen dataset.\n",
    "test_dataset = jobads_encoded['test'] \n",
    "\n",
    "# Create a Trainer instance.\n",
    "classifier = Trainer(model=model, tokenizer=tokenizer)\n",
    "predictions = classifier.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to numpy for further analysis.\n",
    "labels = predictions.label_ids\n",
    "preds = predictions.predictions.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT: fine-tuned 'bert-base-uncased' model for classification \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       193\n",
      "           1       1.00      1.00      1.00        44\n",
      "           2       1.00      1.00      1.00       113\n",
      "\n",
      "    accuracy                           1.00       350\n",
      "   macro avg       1.00      1.00      1.00       350\n",
      "weighted avg       1.00      1.00      1.00       350\n",
      "\n",
      "{'registered_nurse': 0, 'electrician': 1, 'data_analyst': 2}\n"
     ]
    }
   ],
   "source": [
    "# Plot Confusion Matrix.\n",
    "cm_labels = ['registered nurse', 'electrician', 'data analyst']\n",
    "cm_matrix = confusion_matrix(labels, preds)\n",
    "cm_title = 'confusion matrix: BERT (experiment)'\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='crest', xticklabels=cm_labels, yticklabels=cm_labels)\n",
    "\n",
    "plt.title(cm_title, fontsize=14)\n",
    "plt.xlabel('predicted values', fontsize=14)\n",
    "plt.ylabel('true values', fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print detailed classification report.\n",
    "report = classification_report(labels, preds, output_dict=True)\n",
    "report_title = \"CLASSIFICATION REPORT: fine-tuned 'bert-base-uncased' model for classification\"\n",
    "\n",
    "print(report_title, '\\n')\n",
    "print(classification_report(labels, preds))\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculation of classification experimentation with fine-tuning Bert model completed in: : 1 minutes and 41 seconds.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "end = time.time()\n",
    "print(f'The calculation of classification experimentation with fine-tuning Bert model completed in: : {int((end - start)) // 60} minutes and {int((end - start)) % 60} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a text classification pipeline.\n",
    "classifier = pipeline('text-classification', model='ft_bert_temuulen2', tokenizer='ft_bert_temuulen_tokenizer2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'registered_nurse', 'score': 0.9787058234214783}] = 1. I promote health and help people who is sick\n",
      "[{'label': 'data_analyst', 'score': 0.48012831807136536}] = 2. If your outlet isn't working and you don't have a light, you can ask me to fix it.\n",
      "[{'label': 'data_analyst', 'score': 0.8985043168067932}] = 3. All day, I'm sitting in front of the screen, solving problems with my mouse and keyboard\n",
      "[{'label': 'registered_nurse', 'score': 0.8870661854743958}] = 4. I'm familiar with the process of providing injections to individuals.\n",
      "[{'label': 'electrician', 'score': 0.638813316822052}] = 5. If the streetlights fail, I can replace them with new ones.\n",
      "[{'label': 'data_analyst', 'score': 0.9607547521591187}] = 6. I'm familiar with both Python and R, and I use these tools for my work.\n"
     ]
    }
   ],
   "source": [
    "# Test model with random text samples.\n",
    "random_text = [\"1. I promote health and help people who is sick\", \n",
    "               \"2. If your outlet isn't working and you don't have a light, you can ask me to fix it.\", \n",
    "               \"3. All day, I'm sitting in front of the screen, solving problems with my mouse and keyboard\", \n",
    "               \"4. I'm familiar with the process of providing injections to individuals.\",\n",
    "               \"5. If the streetlights fail, I can replace them with new ones.\",\n",
    "               \"6. I'm familiar with both Python and R, and I use these tools for my work.\"]\n",
    "\n",
    "for x in range(len(random_text)):\n",
    "    print(classifier(random_text[x]), '=', random_text[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random sentences employed to evaluate the fine-tuned Bert-base classification model were intentionally vague and concise, aiming to assess the model's capability in challenging scenarios. Nevertheless, the outcomes and associated scores demonstrate that the model excelled, accurately forecasting every sentence with significant confidence levels (average probability score: **0.8041**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'registered_nurse', 'score': 0.9984044432640076}] = registered nurse\n",
      "[{'label': 'electrician', 'score': 0.9907193779945374}] = electrician\n",
      "[{'label': 'data_analyst', 'score': 0.9932025671005249}] = data analyst\n"
     ]
    }
   ],
   "source": [
    "# Test model with job seekers' data.\n",
    "# Load the experiment participants dataset.\n",
    "df_jobseeker = pd.read_csv('data_jobseeker.csv', index_col=None)\n",
    "\n",
    "# Apply minor modifications for further use.\n",
    "df_jobseeker['combined_info'] = df_jobseeker.education + '. ' + df_jobseeker.skill + '. ' + df_jobseeker.experience + '.'\n",
    "df_jobseeker.drop(['education', 'skill', 'experience'], axis=1, inplace=True)\n",
    "\n",
    "for x in range(3):\n",
    "    print(classifier(df_jobseeker.iat[x, -1]), '=', df_jobseeker.iat[x, -2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data from each participant in the experiment was classified and assigned into the appropriate labelled classes with outstanding results.(average probability score: **0.9926**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the timer to track the execution duration.\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*load dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmark_train_bert = df_benchmark_train.copy()\n",
    "df_benchmark_test_bert = df_benchmark_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*preprocess dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'business', 1: 'sci/tech', 2: 'sports', 3: 'world'}\n",
      "{'business': 0, 'sci/tech': 1, 'sports': 2, 'world': 3}\n"
     ]
    }
   ],
   "source": [
    "labels = df_benchmark_train_bert['label'].unique().tolist()\n",
    "num_labels = len(labels)\n",
    "id2label = {id:label for id, label in enumerate(labels)}\n",
    "label2id = {label: id for id, label in enumerate(labels)}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the 'label' column.\n",
    "df_benchmark_train_bert['label_encoded'] = df_benchmark_train_bert.label.map(lambda x: label2id[x.strip()])\n",
    "df_benchmark_test_bert['label_encoded'] = df_benchmark_test_bert.label.map(lambda x: label2id[x.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE PROPORTION OF TOTAL LABEL ID IN A TRAIN DATASET:\n",
      "0    0.25\n",
      "1    0.25\n",
      "2    0.25\n",
      "3    0.25\n",
      "Name: label_encoded, dtype: float64 \n",
      "\n",
      "THE COUNT OF TOTAL LABEL ID IN A TRAIN DATASET:\n",
      "0    30000\n",
      "1    30000\n",
      "2    30000\n",
      "3    30000\n",
      "Name: label_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine the distribution and value counts for the 'label_encoded' column.\n",
    "print('the proportion of total label ID in a train dataset:'.upper())\n",
    "print(df_benchmark_train_bert['label_encoded'].value_counts(normalize=True).sort_index(), '\\n')\n",
    "\n",
    "print('the count of total label ID in a train dataset:'.upper())\n",
    "print(df_benchmark_train_bert['label_encoded'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE PROPORTION OF TOTAL LABEL ID IN A TEST DATASET:\n",
      "0    0.25\n",
      "1    0.25\n",
      "2    0.25\n",
      "3    0.25\n",
      "Name: label_encoded, dtype: float64 \n",
      "\n",
      "THE COUNT OF TOTAL LABEL ID IN A TEST DATASET:\n",
      "0    1900\n",
      "1    1900\n",
      "2    1900\n",
      "3    1900\n",
      "Name: label_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine the distribution and value counts for the 'label_encoded' column.\n",
    "print('the proportion of total label ID in a test dataset:'.upper())\n",
    "print(df_benchmark_test_bert['label_encoded'].value_counts(normalize=True).sort_index(), '\\n')\n",
    "\n",
    "print('the count of total label ID in a test dataset:'.upper())\n",
    "print(df_benchmark_test_bert['label_encoded'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*train test split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_drop, df_bert_use_train = train_test_split(df_benchmark_train_bert, \n",
    "                                                   test_size=0.01, random_state=630, \n",
    "                                                   stratify=df_benchmark_train_bert['label'])\n",
    "\n",
    "df_bert_drop, df_bert_use_test = train_test_split(df_benchmark_test_bert, \n",
    "                                                   test_size=0.06, random_state=630, \n",
    "                                                   stratify=df_benchmark_test_bert['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING shape: (840, 3)\n",
      "VALIDATION shape: (360, 3)\n",
      "TEST shape: (456, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split the DataFrame into training and testing sets and maintain label proportions.\n",
    "train, validation = train_test_split(df_bert_use_train, test_size=0.3, random_state=630)\n",
    "test = df_bert_use_test.copy()\n",
    "print('TRAINING shape:', train.shape)\n",
    "print('VALIDATION shape:', validation.shape)\n",
    "print('TEST shape:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*convert to Dataset format*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each set to Dataset format.\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "val_dataset = Dataset.from_pandas(validation)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "\n",
    "# Remove '__index_level_0__' feature.\n",
    "train_dataset = train_dataset.remove_columns('__index_level_0__')\n",
    "val_dataset = val_dataset.remove_columns('__index_level_0__')\n",
    "\n",
    "# Create DatasetDict variable.\n",
    "benchmark_text = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test' : test_dataset\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a tokenizer from the 'bert-base-uncased' pretrained model.\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Initialize a BERT-based sequence classification model.\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
    "                                                      num_labels=4,\n",
    "                                                      id2label=id2label,\n",
    "                                                      label2id=label2id)\n",
    "# Move the model to device.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom tokenization function for long and short text.\n",
    "def custom_tokenize(batch, strategy='default', max_length=512):\n",
    "    \n",
    "    tokenized_outputs = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "    for text in batch['text']:\n",
    "        # Tokenize using the default strategy if the text is shorter than the maximum length.\n",
    "        if strategy == 'default':\n",
    "            inputs = tokenizer.encode_plus(text, max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
    "        # Tokenize using the default strategy if the text is longer than the maximum length.\n",
    "        elif strategy == 'head-tail':\n",
    "            tokens = tokenizer.tokenize(text)\n",
    "\n",
    "            head_length = int((max_length - 3) * 0.6)\n",
    "            tail_length = (max_length - 3) - head_length\n",
    "            # If the text is longer than the specified maximum length, split it into head and tail parts.\n",
    "            if len(tokens) > max_length - 2:\n",
    "                head_tokens = tokens[:head_length]\n",
    "                tail_tokens = tokens[-tail_length:]\n",
    "                input_ids = tokenizer.encode_plus(text=' '.join(head_tokens + tail_tokens), max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')['input_ids']\n",
    "                attention_mask = tokenizer.encode_plus(text=' '.join(head_tokens + tail_tokens), max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')['attention_mask']\n",
    "            # If the text is within the maximum length, tokenize it as is.\n",
    "            else:\n",
    "                encoded_plus = tokenizer.encode_plus(text, max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
    "                input_ids, attention_mask = encoded_plus['input_ids'], encoded_plus['attention_mask']\n",
    "            inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "        else:\n",
    "\n",
    "            pass\n",
    "\n",
    "        # Append tokenized input and attention mask to the outputs.\n",
    "        tokenized_outputs['input_ids'].append(inputs['input_ids'].squeeze().tolist())\n",
    "        tokenized_outputs['attention_mask'].append(inputs['attention_mask'].squeeze().tolist())\n",
    "\n",
    "    return tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad41170beda84f0e87a9980869ac73e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb66a7786da046c9ae351d0b533b6723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a98afddd8b49c6ad3fbee04cec9416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/456 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'label_encoded', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 840\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label', 'label_encoded', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 360\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'label_encoded', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 456\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the dataset.\n",
    "benchmark_text_encoded = benchmark_text.map(tokenize, batched=True, batch_size=None)\n",
    "\n",
    "print(benchmark_text_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dataset format to PyTorch tensors.\n",
    "benchmark_text_encoded.set_format('torch', columns=['input_ids', 'attention_mask', 'label_encoded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*manage the loss function for inbalanced text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9589, 1.0000, 1.0345, 1.0096])\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights.\n",
    "labels = train['label_encoded'].unique()\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=labels,\n",
    "                                     y=train['label_encoded'])\n",
    "\n",
    "# Convert the computed class weights to a PyTorch tensor.\n",
    "class_weights = torch.from_numpy(class_weights).float()\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 840\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label', 'labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 360\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'labels', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 456\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Finalise the dataset.\n",
    "benchmark_text_encoded = benchmark_text_encoded.rename_column('label_encoded', 'labels')\n",
    "\n",
    "print(benchmark_text_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom trainer class.\n",
    "class WeightedLossTrainer(Trainer):\n",
    "    \n",
    "    # Override the method for loss computation.\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        labels = inputs.get('labels')\n",
    "        \n",
    "        # Move class weights to device.\n",
    "        class_weights_device = class_weights.to(model.device)\n",
    "        \n",
    "        # Calculate the loss using CrossEntropyLoss function with the computed class weights.\n",
    "        loss_func = nn.CrossEntropyLoss(weight=class_weights_device)\n",
    "        loss = loss_func(logits, labels)\n",
    "        \n",
    "        # Return a tuple containing loss and outputs if 'return_outputs' is True.\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size for training.\n",
    "batch_size = 16\n",
    "\n",
    "# Calculate the number of logging steps based on the dataset size and batch size.\n",
    "logging_steps = len(benchmark_text_encoded['train']) // batch_size\n",
    "\n",
    "# Specify the directory where the trained model and logs will be saved.\n",
    "output_dir = 'ft_bert_temuulen_benchmark'\n",
    "\n",
    "# Create an instance of TrainingArguments to configure the training process.\n",
    "training_args = TrainingArguments(output_dir=output_dir,\n",
    "                                  num_train_epochs=3,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  per_gpu_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  save_strategy='epoch',\n",
    "                                  fp16=True,\n",
    "                                  load_best_model_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the WeightedLossTrainer for training the model.\n",
    "trainer = WeightedLossTrainer(model=model,\n",
    "                              args=training_args,\n",
    "                              train_dataset=benchmark_text_encoded['train'],\n",
    "                              eval_dataset=benchmark_text_encoded['validation'],\n",
    "                              tokenizer=tokenizer,\n",
    "                              compute_metrics= compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc2a24d3b0547ddb2d82dd9b4d1f2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/315 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.176, 'learning_rate': 1.6825396825396828e-05, 'epoch': 0.5}\n",
      "{'loss': 0.5947, 'learning_rate': 1.3523809523809525e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa3221eee274df297e15dfccf97efb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4301092326641083, 'eval_Accuracy': 0.8805555555555555, 'eval_F1': 0.879026233303989, 'eval_Precision': 0.8836533140605471, 'eval_Recall': 0.8778349132039555, 'eval_runtime': 123.1293, 'eval_samples_per_second': 2.924, 'eval_steps_per_second': 0.187, 'epoch': 1.0}\n",
      "{'loss': 0.3283, 'learning_rate': 1.0222222222222223e-05, 'epoch': 1.49}\n",
      "{'loss': 0.23, 'learning_rate': 6.920634920634921e-06, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9daf176ac343299d7c3f78eedfc127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3995382487773895, 'eval_Accuracy': 0.8944444444444445, 'eval_F1': 0.8941220292073973, 'eval_Precision': 0.8963201251861046, 'eval_Recall': 0.8934674701595365, 'eval_runtime': 123.1772, 'eval_samples_per_second': 2.923, 'eval_steps_per_second': 0.187, 'epoch': 2.0}\n",
      "{'loss': 0.1379, 'learning_rate': 3.6190476190476194e-06, 'epoch': 2.48}\n",
      "{'loss': 0.174, 'learning_rate': 3.174603174603175e-07, 'epoch': 2.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0880bc804ad461ab0d22d58879b49b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3919348120689392, 'eval_Accuracy': 0.8972222222222223, 'eval_F1': 0.8972324602625437, 'eval_Precision': 0.8998947287804846, 'eval_Recall': 0.8960447897471654, 'eval_runtime': 122.6064, 'eval_samples_per_second': 2.936, 'eval_steps_per_second': 0.188, 'epoch': 3.0}\n",
      "{'train_runtime': 3307.3645, 'train_samples_per_second': 0.762, 'train_steps_per_second': 0.095, 'train_loss': 0.4379071776829069, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=315, training_loss=0.4379071776829069, metrics={'train_runtime': 3307.3645, 'train_samples_per_second': 0.762, 'train_steps_per_second': 0.095, 'train_loss': 0.4379071776829069, 'epoch': 3.0})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the training.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*save model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned BERT model.\n",
    "trainer.model.save_pretrained('ft_bert_temuulen2_benchmark')\n",
    "\n",
    "# Save the tokenizer used for fine-tuning to the 'ft_bert_temuulen3_tokenizer'.\n",
    "tokenizer.save_pretrained('ft_bert_temuulen_tokenizer2_benchmark')\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*evaluate model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the directory paths for the fine-tuned model and tokenizer.\n",
    "model_path = 'ft_bert_temuulen2_benchmark'\n",
    "tokenizer_path = 'ft_bert_temuulen_tokenizer2_benchmark'\n",
    "\n",
    "# Load the BERT and the tokenizer.\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, output_hidden_states=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92a9e0a48dc4099a49199d9831709a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create a Trainer instance.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m classifier \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m----> 6\u001b[0m predictions \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(test_dataset)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Convert predictions to numpy for further analysis.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m labels \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mlabel_ids\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:3171\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[1;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3168\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3170\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3171\u001b[0m output \u001b[38;5;241m=\u001b[39m eval_loop(\n\u001b[0;32m   3172\u001b[0m     test_dataloader, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m\"\u001b[39m, ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys, metric_key_prefix\u001b[38;5;241m=\u001b[39mmetric_key_prefix\n\u001b[0;32m   3173\u001b[0m )\n\u001b[0;32m   3174\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   3175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:3284\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3281\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[0;32m   3283\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[1;32m-> 3284\u001b[0m loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_step(model, inputs, prediction_loss_only, ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys)\n\u001b[0;32m   3285\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3286\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:3501\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[1;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[0;32m   3499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[0;32m   3500\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3501\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs, return_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3502\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2795\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2794\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2795\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   2796\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2797\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\accelerate\\utils\\operations.py:687\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\accelerate\\utils\\operations.py:675\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[1;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\accelerate\\utils\\operations.py:687\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\accelerate\\utils\\operations.py:675\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[1;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1564\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1564\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(\n\u001b[0;32m   1565\u001b[0m     input_ids,\n\u001b[0;32m   1566\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1567\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   1568\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   1569\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1570\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1571\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1572\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1573\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1574\u001b[0m )\n\u001b[0;32m   1576\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1578\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1012\u001b[0m )\n\u001b[1;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1014\u001b[0m     embedding_output,\n\u001b[0;32m   1015\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   1016\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1017\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1018\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m   1019\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1020\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1021\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1022\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1023\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1024\u001b[0m )\n\u001b[0;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    598\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m         output_attentions,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    608\u001b[0m         hidden_states,\n\u001b[0;32m    609\u001b[0m         attention_mask,\n\u001b[0;32m    610\u001b[0m         layer_head_mask,\n\u001b[0;32m    611\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    612\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    613\u001b[0m         past_key_value,\n\u001b[0;32m    614\u001b[0m         output_attentions,\n\u001b[0;32m    615\u001b[0m     )\n\u001b[0;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    536\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    537\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 539\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, attention_output\n\u001b[0;32m    541\u001b[0m )\n\u001b[0;32m    542\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    544\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:236\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:551\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m--> 551\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m    552\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:451\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 451\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m    452\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load prepared an unseen dataset.\n",
    "test_dataset = benchmark_text_encoded['test'] \n",
    "\n",
    "# Create a Trainer instance.\n",
    "classifier = Trainer(model=model, tokenizer=tokenizer)\n",
    "predictions = classifier.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to numpy for further analysis.\n",
    "labels = predictions.label_ids\n",
    "preds = predictions.predictions.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix.\n",
    "cm_labels = np.unique(np.concatenate((labels, preds)))\n",
    "cm_matrix = confusion_matrix(labels, preds)\n",
    "cm_title = 'confusion matrix: BERT(benchmark)'\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='crest', xticklabels=cm_labels, yticklabels=cm_labels)\n",
    "\n",
    "plt.title(cm_title, fontsize=14)\n",
    "plt.xlabel('predicted values', fontsize=14)\n",
    "plt.ylabel('true values', fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print detailed classification report.\n",
    "report = classification_report(labels, preds, output_dict=True)\n",
    "report_title = 'classification report: BERT(benchmark)'\n",
    "\n",
    "print(report_title, '\\n')\n",
    "print(classification_report(labels, preds))\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculation of classification benchmarking with fine-tuning Bert model completed in: : 25 minutes and 32 seconds.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "end = time.time()\n",
    "print(f'The calculation of classification benchmarking with fine-tuning Bert model completed in: : {int((end - start)) // 60} minutes and {int((end - start)) % 60} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CLASSIFICATION WITH PRE-TRAINED WORD2VEC MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Experimenttion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the timer to track the execution duration.\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*load dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame for experimentation with BERT.\n",
    "df_words2vec = df_experiment.copy()\n",
    "\n",
    "df_words2vec.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialize tools*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Word2Vec model.\n",
    "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Initialize the Logistic Regression model (original approach)\n",
    "clf = LogisticRegression(max_iter=1000, class_weight='balanced')  # Increased max_iter for convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*preprocess and tokenize dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'id2label', 'label2id' variables for mapping the labels.\n",
    "labels = df_words2vec['label'].unique().tolist()\n",
    "num_labels = len(labels)\n",
    "id2label = {id:label for id, label in enumerate(labels)}\n",
    "label2id = {label: id for id, label in enumerate(labels)}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the 'label' column.\n",
    "df_words2vec['label_encoded'] = df_words2vec.label.map(lambda x: label2id[x.strip()])\n",
    "\n",
    "df_words2vec.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing and tokenizing\n",
    "def preprocess_text_word2vec(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Removing punctuation\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words2vec['processed_jd'] = df_words2vec['job_description'].apply(preprocess_text_word2vec)\n",
    "\n",
    "df_words2vec.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*embed text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_tokens(tokens_list, model):\n",
    "    vectors = [model[word] for word in tokens_list if word in model]\n",
    "    if vectors:\n",
    "        # Averaging the vectors (You could choose another aggregation method)\n",
    "        embedding = np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        # Use a zero vector if none of the tokens were found in the Word2Vec model\n",
    "        embedding = np.zeros(model.vector_size)\n",
    "        \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to embed each row's tokens in the DataFrame\n",
    "df_words2vec['vectors'] = df_words2vec['processed_jd'].apply(lambda x: embed_tokens(x, word2vec))\n",
    "# This will add a new column 'word2vec_embedding' where each row contains the aggregated Word2Vec embedding for its tokens\n",
    "\n",
    "print('The shape of the first tensor:', df_words2vec.iat[0, -1].shape, '\\n')\n",
    "print('The shape of the second tensor:', df_words2vec.iat[1, -1].shape, '\\n')\n",
    "print(df_words2vec.iat[0, -1], '\\n')\n",
    "\n",
    "df_words2vec.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*train test split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack(df_words2vec['vectors'].values)  # Convert the list of vectors into a numpy array\n",
    "y = df_words2vec['label_encoded'].values      # Get the target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=630)\n",
    "print('TRAINING shape:', X_train.shape)\n",
    "print('TEST shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*train model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*evaluate model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions.\n",
    "preds = clf.predict(X_test)\n",
    "labels = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('classification report: LOGISTIC REGRESSION (WORD2VEC)\\n\\n', classification_report(labels, preds))\n",
    "\n",
    "cm_labels = ['registered nurse', 'electrician', 'data analyst']\n",
    "cm_matrix = confusion_matrix(labels, preds)\n",
    "cm_title = 'confusion matrix: LOGISTIC REGRESSION (WORD2VEC)'\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='crest', xticklabels=cm_labels, yticklabels=cm_labels)\n",
    "\n",
    "plt.title(cm_title, fontsize=14)\n",
    "plt.xlabel('predicted values', fontsize=14)\n",
    "plt.ylabel('true values', fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f'The calculation of classification experimentation with pre-trained Word2Vec model completed in: : {int((end - start)) // 60} minutes and {int((end - start)) % 60} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the timer to track the execution duration.\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*load dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benc_train_word2vec = df_benchmark_train.copy()\n",
    "df_benc_test_word2vec = df_benchmark_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*preprocess and tokenize dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 'label' column for unique values.\n",
    "labels = df_benc_train_word2vec['label'].unique().tolist()\n",
    "num_labels = len(labels)\n",
    "id2label = {id:label for id, label in enumerate(labels)}\n",
    "label2id = {label: id for id, label in enumerate(labels)}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the 'label' column.\n",
    "df_benc_train_word2vec['label_encoded'] = df_benc_train_word2vec.label.map(lambda x: label2id[x.strip()])\n",
    "df_benc_test_word2vec['label_encoded'] = df_benc_test_word2vec.label.map(lambda x: label2id[x.strip()])\n",
    "\n",
    "df_benchmark_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benc_train_word2vec['processed_text'] = df_benc_train_word2vec['text'].apply(preprocess_text_word2vec)\n",
    "df_benc_test_word2vec['processed_text'] = df_benc_test_word2vec['text'].apply(preprocess_text_word2vec)\n",
    "\n",
    "df_benc_test_word2vec.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*embed text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benc_train_word2vec['vectors'] = df_benc_train_word2vec['processed_text'].apply(lambda x: embed_tokens(x, word2vec))\n",
    "df_benc_test_word2vec['vectors'] = df_benc_test_word2vec['processed_text'].apply(lambda x: embed_tokens(x, word2vec))\n",
    "\n",
    "df_benc_train_word2vec.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*train test split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_df, df_word2vec_use_train = train_test_split(df_benc_train_word2vec, \n",
    "                                                   test_size=0.01, random_state=630, \n",
    "                                                   stratify=df_benc_train_word2vec['label'])\n",
    "\n",
    "drop_df, df_word2vec_use_test = train_test_split(df_benc_test_word2vec, \n",
    "                                                   test_size=0.06, random_state=630, \n",
    "                                                   stratify=df_benc_test_word2vec['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into training and testing sets and maintain label proportions.\n",
    "train, drop_val = train_test_split(df_word2vec_use_train, test_size=0.3, random_state=630)\n",
    "test = df_word2vec_use_test.copy()\n",
    "print('TRAINING shape:', train.shape)\n",
    "print('TEST shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.stack(train['vectors'].values)\n",
    "X_test = np.stack(test['vectors'].values)\n",
    "y_train = train['label_encoded'].copy()\n",
    "y_test = test['label_encoded'].copy()\n",
    "print('TRAINING shape:', X_train.shape)\n",
    "print('TEST shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*train model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*evaluate model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can now use log_reg to make predictions and evaluate the model\n",
    "preds = clf.predict(X_test)\n",
    "labels = y_test\n",
    "\n",
    "print('classification report: LOGISTIC REGRESSION (PRETRAINED WORD2WEC)\\n\\n', classification_report(labels, preds))\n",
    "\n",
    "cm_labels = np.unique(np.concatenate((labels, preds)))\n",
    "cm_matrix = confusion_matrix(labels, preds)\n",
    "cm_title = 'confusion matrix: LOGISTIC REGRESSION (PRETRAINED WORD2WEC)'\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='crest', xticklabels=cm_labels, yticklabels=cm_labels)\n",
    "\n",
    "plt.title(cm_title, fontsize=14)\n",
    "plt.xlabel('predicted values', fontsize=14)\n",
    "plt.ylabel('true values', fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f'The calculation of classification benchmarking with pre-trained Word2Vec model completed in: : {int((end - start)) // 60} minutes and {int((end - start)) % 60} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CLASSIFICATION WITH TF-IDF AND BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the timer to track the execution duration.\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*load dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original DataFrame for experimentation with BERT.\n",
    "df_tfidf = df_experiment.copy()\n",
    "\n",
    "df_tfidf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*load tools*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary NLTK data.\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*preprocess and tokenize dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Removing punctuation\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Removing stopwords and lemmatization\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    processed_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    # Re-joining tokens\n",
    "    processed_text = ' '.join(processed_tokens)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'id2label', 'label2id' variables for mapping the labels.\n",
    "labels = df_tfidf['label'].unique().tolist()\n",
    "num_labels = len(labels)\n",
    "id2label = {id:label for id, label in enumerate(labels)}\n",
    "label2id = {label: id for id, label in enumerate(labels)}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the 'label' column.\n",
    "df_tfidf['label_encoded'] = df_tfidf.label.map(lambda x: label2id[x.strip()])\n",
    "\n",
    "df_tfidf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf['processed_jd'] = df_tfidf['job_description'].apply(preprocess_text)\n",
    "\n",
    "df_tfidf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*train test split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_tfidf['processed_jd'], df_tfidf['label_encoded'], test_size=0.3, random_state=630)\n",
    "print('TOTAL shape:', df_tfidf.shape)\n",
    "print('TRAINING shape:', X_train.shape)\n",
    "print('TEST shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*embed text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer()\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = hstack([X_train_bow, X_train_tfidf])\n",
    "X_test_combined = hstack([X_test_bow, X_test_tfidf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*train model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model with combined features\n",
    "clf.fit(X_train_combined, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*evaluate model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "preds = clf.predict(X_test_combined)\n",
    "labels = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('classification report: LOGISTIC REGRESSION (TF-IDF + BOW)\\n\\n', classification_report(labels, preds))\n",
    "\n",
    "cm_labels = ['registered nurse', 'electrician', 'data analyst']\n",
    "cm_matrix = confusion_matrix(labels, preds)\n",
    "cm_title = 'confusion matrix: LOGISTIC REGRESSION (TF-IDF + BOW)'\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='crest', xticklabels=cm_labels, yticklabels=cm_labels)\n",
    "\n",
    "plt.title(cm_title, fontsize=14)\n",
    "plt.xlabel('predicted values', fontsize=14)\n",
    "plt.ylabel('true values', fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f'The calculation of classification experimentation with TF-IDF and BoW completed in: : {int((end - start)) // 60} minutes and {int((end - start)) % 60} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the timer to track the execution duration.\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*load dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benc_train_tfidf = df_benchmark_train.copy()\n",
    "df_benc_test_tfidf = df_benchmark_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*preprocess and tokenize dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 'label' column for unique values.\n",
    "labels = df_benc_train_tfidf['label'].unique().tolist()\n",
    "num_labels = len(labels)\n",
    "id2label = {id:label for id, label in enumerate(labels)}\n",
    "label2id = {label: id for id, label in enumerate(labels)}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the 'label' column.\n",
    "df_benc_train_tfidf['label_encoded'] = df_benc_train_tfidf.label.map(lambda x: label2id[x.strip()])\n",
    "df_benc_test_tfidf['label_encoded'] = df_benc_test_tfidf.label.map(lambda x: label2id[x.strip()])\n",
    "\n",
    "df_benc_test_tfidf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benc_train_tfidf['processed_text'] = df_benc_train_tfidf['text'].apply(preprocess_text)\n",
    "df_benc_test_tfidf['processed_text'] = df_benc_test_tfidf['text'].apply(preprocess_text)\n",
    "\n",
    "df_benc_test_tfidf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*train test split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_df, df_tfidf_use_train = train_test_split(df_benc_train_tfidf, \n",
    "                                                   test_size=0.01, random_state=630, \n",
    "                                                   stratify=df_benc_train_tfidf['label'])\n",
    "\n",
    "drop_df, df_tfidf_use_test = train_test_split(df_benc_test_tfidf, \n",
    "                                                   test_size=0.06, random_state=630, \n",
    "                                                   stratify=df_benc_test_tfidf['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into training and testing sets and maintain label proportions.\n",
    "train, drop_val = train_test_split(df_tfidf_use_train, test_size=0.3, random_state=630)\n",
    "test = df_tfidf_use_test.copy()\n",
    "print('TRAINING shape:', train.shape)\n",
    "print('TEST shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_tfidf_use_train['processed_text'].copy()\n",
    "X_test = df_tfidf_use_test['processed_text'].copy()\n",
    "y_train = df_tfidf_use_train['label_encoded'].copy()\n",
    "y_test = df_tfidf_use_test['label_encoded'].copy()\n",
    "print('TRAINING shape:', X_train.shape)\n",
    "print('TEST shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*embed text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = hstack([X_train_bow, X_train_tfidf])\n",
    "X_test_combined = hstack([X_test_bow, X_test_tfidf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*train model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model with combined features\n",
    "clf.fit(X_train_combined, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*evaluate model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "preds = clf.predict(X_test_combined)\n",
    "labels = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('classification report: LOGISTIC REGRESSION (TF-IDF + BOW)\\n\\n', classification_report(labels, preds))\n",
    "\n",
    "cm_labels = np.unique(np.concatenate((labels, preds)))\n",
    "cm_matrix = confusion_matrix(labels, preds)\n",
    "cm_title = 'confusion matrix: LOGISTIC REGRESSION (TF-IDF + BOW)'\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='crest', xticklabels=cm_labels, yticklabels=cm_labels)\n",
    "\n",
    "plt.title(cm_title, fontsize=14)\n",
    "plt.xlabel('predicted values', fontsize=14)\n",
    "plt.ylabel('true values', fontsize=14)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f'The calculation of classification benchmarking with with TF-IDF and BoW completed in: : {int((end - start)) // 60} minutes and {int((end - start)) % 60} seconds.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

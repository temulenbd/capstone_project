{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART III: CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. GENERAL\n",
    "\n",
    "### 0.1. Load the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nessesary libraries.\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "import gpustat\n",
    "import platform\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "from torch import nn\n",
    "from transformers import Trainer\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from transformers import BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Check the computational environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOWS VERSION: Windows-10-10.0.22631-SP0\n",
      "PYTHON VERSION: 3.11.4 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 13:38:37) [MSC v.1916 64 bit (AMD64)]\n",
      "CPU CORE: 4\n",
      "CPU SPEED: scpufreq(current=2496.0, min=0.0, max=2496.0)\n",
      "GPU: NVIDIA GeForce GTX 1650\n",
      "RAM: 31.87 GB\n",
      "HARD DRIVE: 237.45 GB\n"
     ]
    }
   ],
   "source": [
    "# List the software and hardware configurations used for conducting the experiment.\n",
    "print('WINDOWS VERSION:', platform.platform())\n",
    "print('PYTHON VERSION:', sys.version)\n",
    "print('CPU CORE:', psutil.cpu_count(logical=False))\n",
    "print('CPU SPEED:', psutil.cpu_freq())\n",
    "print('GPU:', gpustat.new_query().gpus[0].name)\n",
    "print(f'RAM: {psutil.virtual_memory().total/(1024 ** 3):.2f} GB')\n",
    "print(f\"HARD DRIVE: {psutil.disk_usage('/').total/(1024 ** 3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Load the main dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*experiment dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the experiment dataset is: (1166, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     job_description             label\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse\n",
       "1  create a better future for yourself  recruitne...  registered_nurse"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset as pandas data frame.\n",
    "df_experiment = pd.read_csv('data_jobads_final.csv', index_col=None)\n",
    "\n",
    "# Apply small modifications.\n",
    "df_experiment['job_description'] = df_experiment['job_description'].str.replace('\\n', ' ')\n",
    "df_experiment = df_experiment.dropna().reset_index(drop=True)\n",
    "df_experiment = df_experiment.iloc[:,-2:]\n",
    "\n",
    "print('The shape of the experiment dataset is:', df_experiment.shape)\n",
    "df_experiment.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*benchmark dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets as pandas data frame.\n",
    "df_benchmark_train = pd.read_csv('ag_news_train.csv', index_col=None)\n",
    "df_benchmark_test = pd.read_csv('ag_news_test.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the train dataset for benchmark is: (120000, 2)\n",
      "The shape of the test dataset for benchmark is: (7600, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reut...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Re...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0   Wall St. Bears Claw Back Into the Black (Reut...  business\n",
       "1   Carlyle Looks Toward Commercial Aerospace (Re...  business"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The shape of the train dataset for benchmark is:', df_benchmark_train.shape)\n",
    "print('The shape of the test dataset for benchmark is:', df_benchmark_test.shape)\n",
    "df_benchmark_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CLASSIFICATION WITH FINE-TUNED BERT MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the timer to track the execution duration.\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*load the dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     job_description             label\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse\n",
       "1  create a better future for yourself  recruitne...  registered_nurse"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the original DataFrame for experimentation with BERT.\n",
    "df_bert = df_experiment.copy()\n",
    "\n",
    "df_bert.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*preprocess the dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'registered_nurse', 1: 'electrician', 2: 'data_analyst'}\n",
      "{'registered_nurse': 0, 'electrician': 1, 'data_analyst': 2}\n"
     ]
    }
   ],
   "source": [
    "# Create 'id2label', 'label2id' variables for mapping the labels.\n",
    "labels = df_experiment['label'].unique().tolist()\n",
    "num_labels = len(labels)\n",
    "id2label = {id:label for id, label in enumerate(labels)}\n",
    "label2id = {label: id for id, label in enumerate(labels)}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     job_description             label  \\\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "1  create a better future for yourself  recruitne...  registered_nurse   \n",
       "\n",
       "   label_encoded  \n",
       "0              0  \n",
       "1              0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the 'label' column.\n",
    "df_experiment['label_encoded'] = df_experiment.label.map(lambda x: label2id[x.strip()])\n",
    "\n",
    "df_experiment.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE PROPORTION OF TOTAL LABEL ID:\n",
      "0    0.552316\n",
      "1    0.125214\n",
      "2    0.322470\n",
      "Name: label_encoded, dtype: float64 \n",
      "\n",
      "THE COUNT OF TOTAL LABEL ID:\n",
      "0    644\n",
      "2    376\n",
      "1    146\n",
      "Name: label_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine the distribution and value counts for the 'label_encoded' column.\n",
    "print(\"the proportion of total label ID:\".upper())\n",
    "print(df_experiment['label_encoded'].value_counts(normalize=True).sort_index(), '\\n')\n",
    "\n",
    "print(\"the count of total label ID:\".upper())\n",
    "print(df_experiment['label_encoded'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialize the gpu* (optional)\n",
    "\n",
    "To enhance the effectiveness of managing matrix and tensor operations, the CUDA device was created. This capability represents a key advantage of utilizing the BERT model within the Torch framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA was successfully installed and compiled on my device.\n",
      "CUDA device name is: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "# Check whether CUDA is accessible and, if so, create a CUDA device.\n",
    "cuda_available = torch.cuda.is_available()\n",
    "cuda_device= torch.cuda.get_device_name(0)\n",
    "\n",
    "if cuda_available == True:\n",
    "    device = torch.device('cuda')\n",
    "    print('CUDA was successfully installed and compiled on my device.')\n",
    "    print('CUDA device name is:', cuda_device)\n",
    "else:\n",
    "    print('Cuda in not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*train test split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL shape: (1166, 3)\n",
      "TRAINING shape: (816, 3)\n",
      "VALIDATION shape: (175, 3)\n",
      "TEST shape: (175, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split the DataFrame into training and testing sets and maintain label proportions.\n",
    "train, validation_test = train_test_split(df_experiment, test_size=0.3, random_state=630, stratify=df_experiment['label'])\n",
    "test, validation = train_test_split(validation_test, test_size=0.5, random_state=630, stratify=validation_test['label'])\n",
    "\n",
    "print('TOTAL shape:', df_experiment.shape)\n",
    "print('TRAINING shape:', train.shape)\n",
    "print('VALIDATION shape:', validation.shape)\n",
    "print('TEST shape:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*convert to Dataset format*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each set to Dataset format.\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "val_dataset = Dataset.from_pandas(validation)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "\n",
    "# Remove '__index_level_0__' feature.\n",
    "train_dataset = train_dataset.remove_columns('__index_level_0__')\n",
    "val_dataset = val_dataset.remove_columns('__index_level_0__')\n",
    "test_dataset = test_dataset.remove_columns('__index_level_0__')\n",
    "\n",
    "# Create DatasetDict variable.\n",
    "jobads = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test' : test_dataset\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialize the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a tokenizer from the 'bert-base-uncased' pretrained model.\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Initialize a BERT-based sequence classification model.\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
    "                                                      num_labels=3,\n",
    "                                                      id2label=id2label,\n",
    "                                                      label2id=label2id)\n",
    "# Move the model to device.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*tokenize the text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom tokenization function for processing long and short texts.\n",
    "def custom_tokenize(batch, strategy='default', max_length=512):\n",
    "    \n",
    "    tokenized_outputs = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "    for text in batch['job_description']:\n",
    "        # Tokenize using the default strategy if the text is shorter than the maximum length.\n",
    "        if strategy == 'default':\n",
    "            inputs = tokenizer.encode_plus(text, max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
    "        # Tokenize using the default strategy if the text is longer than the maximum length.\n",
    "        elif strategy == 'head-tail':\n",
    "            tokens = tokenizer.tokenize(text)\n",
    "\n",
    "            head_length = int((max_length - 3) * 0.6)\n",
    "            tail_length = (max_length - 3) - head_length\n",
    "            # If the text is longer than the specified maximum length, split it into head and tail parts.\n",
    "            if len(tokens) > max_length - 2:\n",
    "                head_tokens = tokens[:head_length]\n",
    "                tail_tokens = tokens[-tail_length:]\n",
    "                input_ids = tokenizer.encode_plus(text=' '.join(head_tokens + tail_tokens), max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')['input_ids']\n",
    "                attention_mask = tokenizer.encode_plus(text=\" \".join(head_tokens + tail_tokens), max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')['attention_mask']\n",
    "            # If the text is within the maximum length, tokenize it as is.\n",
    "            else:\n",
    "                encoded_plus = tokenizer.encode_plus(text, max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
    "                input_ids, attention_mask = encoded_plus['input_ids'], encoded_plus['attention_mask']\n",
    "            inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "        else:\n",
    "\n",
    "            pass\n",
    "\n",
    "        # Append tokenized input and attention mask to the outputs.\n",
    "        tokenized_outputs['input_ids'].append(inputs['input_ids'].squeeze().tolist())\n",
    "        tokenized_outputs['attention_mask'].append(inputs['attention_mask'].squeeze().tolist())\n",
    "\n",
    "    return tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a costum function for tokenization using the 'head-tail' strategy.\n",
    "def tokenize(examples):\n",
    "    return custom_tokenize(examples, strategy='head-tail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c177db8fac454fa266c2daed43fe9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/816 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ad1c476fa84a19bda154ec2c435469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/175 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd65253933b4614af89f124458ff2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/175 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['job_description', 'label', 'label_encoded', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 816\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['job_description', 'label', 'label_encoded', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 175\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['job_description', 'label', 'label_encoded', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 175\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the dataset.\n",
    "jobads_encoded = jobads.map(tokenize, batched=True, batch_size=None)\n",
    "\n",
    "print(jobads_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dataset format to PyTorch tensors.\n",
    "jobads_encoded.set_format('torch', columns=['input_ids', 'attention_mask', 'label_encoded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*manage the loss function with inbalanced text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6031, 1.0342, 2.6667])\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights.\n",
    "labels = train['label_encoded'].unique()\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=labels,\n",
    "                                     y=train['label_encoded'])\n",
    "\n",
    "# Convert the computed class weights to a PyTorch tensor.\n",
    "class_weights = torch.from_numpy(class_weights).float()\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['job_description', 'label', 'labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 816\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['job_description', 'label', 'labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 175\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['job_description', 'label', 'labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 175\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Finalise the dataset.\n",
    "jobads_encoded = jobads_encoded.rename_column('label_encoded', 'labels')\n",
    "\n",
    "print(jobads_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom trainer class.\n",
    "class WeightedLossTrainer(Trainer):\n",
    "    \n",
    "    # Override the method for loss computation.\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        labels = inputs.get('labels')\n",
    "        \n",
    "        # Move class weights to device.\n",
    "        class_weights_device = class_weights.to(model.device)\n",
    "        \n",
    "        # Calculate the loss using CrossEntropyLoss function with the computed class weights.\n",
    "        loss_func = nn.CrossEntropyLoss(weight=class_weights_device)\n",
    "        loss = loss_func(logits, labels)\n",
    "        \n",
    "        # Return a tuple containing loss and outputs if 'return_outputs' is True.\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*manage training argumets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a costum function to compute accuracy, F1, precision, and recall for a given set of predictions.\n",
    "def compute_metrics(pred):\n",
    "  \n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  \n",
    "  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  \n",
    "  return {'Accuracy': acc,\n",
    "          'F1': f1,\n",
    "          'Precision': precision,\n",
    "          'Recall': recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size for training.\n",
    "batch_size = 128\n",
    "\n",
    "# Calculate the number of logging steps based on the dataset size and batch size.\n",
    "logging_steps = len(jobads_encoded['train']) // batch_size\n",
    "\n",
    "# Specify the directory where the trained model and logs will be saved.\n",
    "output_dir = 'ft_bert_temuulen'\n",
    "\n",
    "# Create an instance of TrainingArguments to configure the training process.\n",
    "training_args = TrainingArguments(output_dir=output_dir,\n",
    "                                  num_train_epochs=3,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  per_gpu_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  save_strategy='epoch',\n",
    "                                  fp16=True,\n",
    "                                  load_best_model_at_end=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*fine-tune the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the WeightedLossTrainer for training the model.\n",
    "trainer = WeightedLossTrainer(model=model,\n",
    "                              args=training_args,\n",
    "                              train_dataset=jobads_encoded['train'],\n",
    "                              eval_dataset=jobads_encoded['validation'],\n",
    "                              tokenizer=tokenizer,\n",
    "                              compute_metrics= compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41982f2ff068416a810e2d19eb5348f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Start the training.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1540\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   1541\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   1542\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   1543\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   1544\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1869\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1875\u001b[0m ):\n\u001b[0;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2781\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2779\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   2780\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[0;32m   2783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:1962\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   1960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1961\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1962\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1963\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1964\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\temulenbd\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    267\u001b[0m     tensors,\n\u001b[0;32m    268\u001b[0m     grad_tensors_,\n\u001b[0;32m    269\u001b[0m     retain_graph,\n\u001b[0;32m    270\u001b[0m     create_graph,\n\u001b[0;32m    271\u001b[0m     inputs,\n\u001b[0;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start the training.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*save the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned BERT model.\n",
    "trainer.model.save_pretrained('ft_bert_temuulen2')\n",
    "\n",
    "# Save the tokenizer used for fine-tuning to the 'ft_bert_temuulen3_tokenizer'.\n",
    "tokenizer.save_pretrained('ft_bert_temuulen_tokenizer2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*evaluate the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory paths for the fine-tuned model and tokenizer.\n",
    "model_path = 'ft_bert_temuulen2'\n",
    "tokenizer_path = 'ft_bert_temuulen_tokenizer2'\n",
    "\n",
    "# Load the BERT and the tokenizer.\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59e074d5e474180989b2ec93162f8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load prepared an unseen dataset.\n",
    "test_dataset = jobads_encoded['test'] \n",
    "\n",
    "# Create a Trainer instance.\n",
    "classifier = Trainer(model=model, tokenizer=tokenizer)\n",
    "predictions = classifier.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to numpy for further analysis.\n",
    "labels = predictions.label_ids\n",
    "preds = predictions.predictions.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(23, 28, 66)"
          ],
          [
           0.09090909090909091,
           "rgb(41, 58, 143)"
          ],
          [
           0.18181818181818182,
           "rgb(11, 102, 189)"
          ],
          [
           0.2727272727272727,
           "rgb(69, 144, 185)"
          ],
          [
           0.36363636363636365,
           "rgb(142, 181, 194)"
          ],
          [
           0.45454545454545453,
           "rgb(210, 216, 219)"
          ],
          [
           0.5454545454545454,
           "rgb(230, 210, 204)"
          ],
          [
           0.6363636363636364,
           "rgb(213, 157, 137)"
          ],
          [
           0.7272727272727273,
           "rgb(196, 101, 72)"
          ],
          [
           0.8181818181818182,
           "rgb(172, 43, 36)"
          ],
          [
           0.9090909090909091,
           "rgb(120, 14, 40)"
          ],
          [
           1,
           "rgb(60, 9, 17)"
          ]
         ],
         "reversescale": false,
         "showscale": true,
         "type": "heatmap",
         "x": [
          "registered nurse",
          "electrician",
          "data analyst"
         ],
         "y": [
          "registered nurse",
          "electrician",
          "data analyst"
         ],
         "z": [
          [
           96,
           0,
           0
          ],
          [
           0,
           22,
           0
          ],
          [
           0,
           0,
           57
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "96",
          "x": "registered nurse",
          "xref": "x",
          "y": "registered nurse",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0",
          "x": "electrician",
          "xref": "x",
          "y": "registered nurse",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0",
          "x": "data analyst",
          "xref": "x",
          "y": "registered nurse",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0",
          "x": "registered nurse",
          "xref": "x",
          "y": "electrician",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "22",
          "x": "electrician",
          "xref": "x",
          "y": "electrician",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0",
          "x": "data analyst",
          "xref": "x",
          "y": "electrician",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0",
          "x": "registered nurse",
          "xref": "x",
          "y": "data analyst",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0",
          "x": "electrician",
          "xref": "x",
          "y": "data analyst",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "57",
          "x": "data analyst",
          "xref": "x",
          "y": "data analyst",
          "yref": "y"
         }
        ],
        "height": 700,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "CONFUSION MATRIX: fine-tuned 'bert-base-uncased' model for classification",
         "x": 0.5
        },
        "width": 700,
        "xaxis": {
         "dtick": 1,
         "gridcolor": "rgb(0, 0, 0)",
         "side": "bottom",
         "ticks": "",
         "title": {
          "text": "Predicted Value"
         }
        },
        "yaxis": {
         "dtick": 1,
         "tickangle": -90,
         "ticks": "",
         "ticksuffix": "  ",
         "title": {
          "text": "True Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT: fine-tuned 'bert-base-uncased' model for classification \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        96\n",
      "           1       1.00      1.00      1.00        22\n",
      "           2       1.00      1.00      1.00        57\n",
      "\n",
      "    accuracy                           1.00       175\n",
      "   macro avg       1.00      1.00      1.00       175\n",
      "weighted avg       1.00      1.00      1.00       175\n",
      "\n",
      "{'registered_nurse': 0, 'electrician': 1, 'data_analyst': 2}\n"
     ]
    }
   ],
   "source": [
    "# Plot Confusion Matrix.\n",
    "cm_labels = ['registered nurse', 'electrician', 'data analyst']\n",
    "cm_matrix = confusion_matrix(labels, preds)\n",
    "cm_title = \"CONFUSION MATRIX: fine-tuned 'bert-base-uncased' model for classification\"\n",
    "\n",
    "fig = ff.create_annotated_heatmap(z=cm_matrix, \n",
    "                                  x=cm_labels,\n",
    "                                  y=cm_labels, \n",
    "                                  colorscale='balance', \n",
    "                                  showscale=True,\n",
    "                                  annotation_text=cm_matrix)\n",
    "\n",
    "fig.update_layout(width=700, \n",
    "                  height=700, \n",
    "                  title=cm_title, \n",
    "                  title_x=0.5,\n",
    "                  xaxis=dict(title='Predicted Value', side='bottom'), \n",
    "                  yaxis_title='True Value')\n",
    "\n",
    "fig.update_yaxes(tickangle=-90)  \n",
    "    \n",
    "fig.show()\n",
    "\n",
    "# Print detailed classification report.\n",
    "report = classification_report(labels, preds, output_dict=True)\n",
    "report_title = \"CLASSIFICATION REPORT: fine-tuned 'bert-base-uncased' model for classification\"\n",
    "\n",
    "print(report_title, '\\n')\n",
    "print(classification_report(labels, preds))\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a text classification pipeline.\n",
    "classifier = pipeline('text-classification', model='ft_bert_temuulen2', tokenizer='ft_bert_temuulen_tokenizer2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'registered_nurse', 'score': 0.9776366353034973}] = 1. I promote health and help people who is sick\n",
      "[{'label': 'electrician', 'score': 0.9333652257919312}] = 2. If your outlet isn't working and you don't have a light, you can ask me to fix it.\n",
      "[{'label': 'data_analyst', 'score': 0.8441108465194702}] = 3. All day, I'm sitting in front of the screen, solving problems with my mouse and keyboard\n",
      "[{'label': 'registered_nurse', 'score': 0.9447991251945496}] = 4. I'm familiar with the process of providing injections to individuals.\n",
      "[{'label': 'electrician', 'score': 0.9593295454978943}] = 5. If the streetlights fail, I can replace them with new ones.\n",
      "[{'label': 'data_analyst', 'score': 0.9338756203651428}] = 6. I'm familiar with both Python and R, and I use these tools for my work.\n"
     ]
    }
   ],
   "source": [
    "# Test model with random text samples.\n",
    "random_text = [\"1. I promote health and help people who is sick\", \n",
    "               \"2. If your outlet isn't working and you don't have a light, you can ask me to fix it.\", \n",
    "               \"3. All day, I'm sitting in front of the screen, solving problems with my mouse and keyboard\", \n",
    "               \"4. I'm familiar with the process of providing injections to individuals.\",\n",
    "               \"5. If the streetlights fail, I can replace them with new ones.\",\n",
    "               \"6. I'm familiar with both Python and R, and I use these tools for my work.\"]\n",
    "\n",
    "for x in range(len(random_text)):\n",
    "    print(classifier(random_text[x]), '=', random_text[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random sentences employed to evaluate the fine-tuned Bert-base classification model were intentionally vague and concise, aiming to assess the model's capability in challenging scenarios. Nevertheless, the outcomes and associated scores demonstrate that the model excelled, accurately forecasting every sentence with significant confidence levels (average probability score: **0.9322**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'registered_nurse', 'score': 0.9979069232940674}] = registered nurse\n",
      "[{'label': 'electrician', 'score': 0.9958240985870361}] = electrician\n",
      "[{'label': 'data_analyst', 'score': 0.996567964553833}] = data analyst\n"
     ]
    }
   ],
   "source": [
    "# Test model with job seekers' data.\n",
    "# Load the experiment participants dataset.\n",
    "df_jobseeker = pd.read_csv('data_jobseeker.csv', index_col=None)\n",
    "\n",
    "# Apply minor modifications for further use.\n",
    "df_jobseeker['combined_info'] = df_jobseeker.education + '. ' + df_jobseeker.skill + '. ' + df_jobseeker.experience + '.'\n",
    "df_jobseeker.drop(['education', 'skill', 'experience'], axis=1, inplace=True)\n",
    "\n",
    "for x in range(3):\n",
    "    print(classifier(df_jobseeker.iat[x, -1]), '=', df_jobseeker.iat[x, -2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data from each participant in the experiment was classified and assigned into the appropriate labelled classes with outstanding results.(average probability score: **0.9968**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmark_train_bert = df_benchmark_train.copy()\n",
    "df_benchmark_test_bert = df_benchmark_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'business', 1: 'sci/tech', 2: 'sports', 3: 'world'}\n",
      "{'business': 0, 'sci/tech': 1, 'sports': 2, 'world': 3}\n"
     ]
    }
   ],
   "source": [
    "labels = df_benchmark_train_bert['label'].unique().tolist()\n",
    "num_labels = len(labels)\n",
    "id2label = {id:label for id, label in enumerate(labels)}\n",
    "label2id = {label: id for id, label in enumerate(labels)}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the 'label' column.\n",
    "df_benchmark_train_bert['label_encoded'] = df_benchmark_train_bert.label.map(lambda x: label2id[x.strip()])\n",
    "df_benchmark_test_bert['label_encoded'] = df_benchmark_test_bert.label.map(lambda x: label2id[x.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE PROPORTION OF TOTAL LABEL ID IN A TRAIN DATASET:\n",
      "0    0.25\n",
      "1    0.25\n",
      "2    0.25\n",
      "3    0.25\n",
      "Name: label_encoded, dtype: float64 \n",
      "\n",
      "THE COUNT OF TOTAL LABEL ID IN A TRAIN DATASET:\n",
      "0    30000\n",
      "1    30000\n",
      "2    30000\n",
      "3    30000\n",
      "Name: label_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine the distribution and value counts for the 'label_encoded' column.\n",
    "print('the proportion of total label ID in a train dataset:'.upper())\n",
    "print(df_benchmark_train_bert['label_encoded'].value_counts(normalize=True).sort_index(), '\\n')\n",
    "\n",
    "print('the count of total label ID in a train dataset:'.upper())\n",
    "print(df_benchmark_train_bert['label_encoded'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE PROPORTION OF TOTAL LABEL ID IN A TEST DATASET:\n",
      "0    0.25\n",
      "1    0.25\n",
      "2    0.25\n",
      "3    0.25\n",
      "Name: label_encoded, dtype: float64 \n",
      "\n",
      "THE COUNT OF TOTAL LABEL ID IN A TEST DATASET:\n",
      "0    1900\n",
      "1    1900\n",
      "2    1900\n",
      "3    1900\n",
      "Name: label_encoded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine the distribution and value counts for the 'label_encoded' column.\n",
    "print('the proportion of total label ID in a test dataset:'.upper())\n",
    "print(df_benchmark_test_bert['label_encoded'].value_counts(normalize=True).sort_index(), '\\n')\n",
    "\n",
    "print('the count of total label ID in a test dataset:'.upper())\n",
    "print(df_benchmark_test_bert['label_encoded'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_drop, df_bert_use_train = train_test_split(df_benchmark_train_bert, \n",
    "                                                   test_size=0.01, random_state=630, \n",
    "                                                   stratify=df_benchmark_train_bert['label'])\n",
    "\n",
    "df_bert_drop, df_bert_use_test = train_test_split(df_benchmark_test_bert, \n",
    "                                                   test_size=0.06, random_state=630, \n",
    "                                                   stratify=df_benchmark_test_bert['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING shape: (840, 3)\n",
      "VALIDATION shape: (360, 3)\n",
      "TEST shape: (456, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split the DataFrame into training and testing sets and maintain label proportions.\n",
    "train, validation = train_test_split(df_bert_use_train, test_size=0.3, random_state=630)\n",
    "test = df_bert_use_test\n",
    "print('TRAINING shape:', train.shape)\n",
    "print('VALIDATION shape:', validation.shape)\n",
    "print('TEST shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each set to Dataset format.\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "val_dataset = Dataset.from_pandas(validation)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "\n",
    "# Remove '__index_level_0__' feature.\n",
    "train_dataset = train_dataset.remove_columns('__index_level_0__')\n",
    "val_dataset = val_dataset.remove_columns('__index_level_0__')\n",
    "\n",
    "# Create DatasetDict variable.\n",
    "benchmark_text = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test' : test_dataset\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_encoded'],\n",
       "        num_rows: 840\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_encoded'],\n",
       "        num_rows: 360\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_encoded', '__index_level_0__'],\n",
       "        num_rows: 456\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a tokenizer from the 'bert-base-uncased' pretrained model.\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Initialize a BERT-based sequence classification model.\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
    "                                                      num_labels=4,\n",
    "                                                      id2label=id2label,\n",
    "                                                      label2id=label2id)\n",
    "# Move the model to device.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom tokenization function for long and short text.\n",
    "def custom_tokenize(batch, strategy='default', max_length=512):\n",
    "    \n",
    "    tokenized_outputs = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "    for text in batch['text']:\n",
    "        # Tokenize using the default strategy if the text is shorter than the maximum length.\n",
    "        if strategy == 'default':\n",
    "            inputs = tokenizer.encode_plus(text, max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
    "        # Tokenize using the default strategy if the text is longer than the maximum length.\n",
    "        elif strategy == 'head-tail':\n",
    "            tokens = tokenizer.tokenize(text)\n",
    "\n",
    "            head_length = int((max_length - 3) * 0.6)\n",
    "            tail_length = (max_length - 3) - head_length\n",
    "            # If the text is longer than the specified maximum length, split it into head and tail parts.\n",
    "            if len(tokens) > max_length - 2:\n",
    "                head_tokens = tokens[:head_length]\n",
    "                tail_tokens = tokens[-tail_length:]\n",
    "                input_ids = tokenizer.encode_plus(text=' '.join(head_tokens + tail_tokens), max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')['input_ids']\n",
    "                attention_mask = tokenizer.encode_plus(text=\" \".join(head_tokens + tail_tokens), max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')['attention_mask']\n",
    "            # If the text is within the maximum length, tokenize it as is.\n",
    "            else:\n",
    "                encoded_plus = tokenizer.encode_plus(text, max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
    "                input_ids, attention_mask = encoded_plus['input_ids'], encoded_plus['attention_mask']\n",
    "            inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "        else:\n",
    "\n",
    "            pass\n",
    "\n",
    "        # Append tokenized input and attention mask to the outputs.\n",
    "        tokenized_outputs['input_ids'].append(inputs['input_ids'].squeeze().tolist())\n",
    "        tokenized_outputs['attention_mask'].append(inputs['attention_mask'].squeeze().tolist())\n",
    "\n",
    "    return tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a costum function for tokenization using the 'head-tail' strategy.\n",
    "def tokenize(examples):\n",
    "    return custom_tokenize(examples, strategy='head-tail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64c417026784ccbb6e12c8927aadbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/840 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f44a6d6b7a7464980213885184f8d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f79cc0cd6264d18ab3999d4500f021b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/456 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'label_encoded', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 840\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label', 'label_encoded', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 360\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'label_encoded', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 456\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the dataset.\n",
    "benchmark_text_encoded = benchmark_text.map(tokenize, batched=True, batch_size=None)\n",
    "\n",
    "print(benchmark_text_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dataset format to PyTorch tensors.\n",
    "benchmark_text_encoded.set_format('torch', columns=['input_ids', 'attention_mask', 'label_encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9589, 1.0000, 1.0345, 1.0096])\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights.\n",
    "labels = train['label_encoded'].unique()\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=labels,\n",
    "                                     y=train['label_encoded'])\n",
    "\n",
    "# Convert the computed class weights to a PyTorch tensor.\n",
    "class_weights = torch.from_numpy(class_weights).float()\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 840\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label', 'labels', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 360\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'labels', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 456\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Finalise the dataset.\n",
    "benchmark_text_encoded = benchmark_text_encoded.rename_column('label_encoded', 'labels')\n",
    "\n",
    "print(benchmark_text_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom trainer class.\n",
    "class WeightedLossTrainer(Trainer):\n",
    "    \n",
    "    # Override the method for loss computation.\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        labels = inputs.get('labels')\n",
    "        \n",
    "        # Move class weights to device.\n",
    "        class_weights_device = class_weights.to(model.device)\n",
    "        \n",
    "        # Calculate the loss using CrossEntropyLoss function with the computed class weights.\n",
    "        loss_func = nn.CrossEntropyLoss(weight=class_weights_device)\n",
    "        loss = loss_func(logits, labels)\n",
    "        \n",
    "        # Return a tuple containing loss and outputs if 'return_outputs' is True.\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a costum function to compute accuracy, F1, precision, and recall for a given set of predictions.\n",
    "def compute_metrics(pred):\n",
    "  \n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  \n",
    "  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  \n",
    "  return {'Accuracy': acc,\n",
    "          'F1': f1,\n",
    "          'Precision': precision,\n",
    "          'Recall': recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size for training.\n",
    "batch_size = 128\n",
    "\n",
    "# Calculate the number of logging steps based on the dataset size and batch size.\n",
    "logging_steps = len(benchmark_text_encoded['train']) // batch_size\n",
    "\n",
    "# Specify the directory where the trained model and logs will be saved.\n",
    "output_dir = 'ft_bert_temuulen_benchmark'\n",
    "\n",
    "# Create an instance of TrainingArguments to configure the training process.\n",
    "training_args = TrainingArguments(output_dir=output_dir,\n",
    "                                  num_train_epochs=3,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  per_gpu_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  save_strategy='epoch',\n",
    "                                  fp16=True,\n",
    "                                  load_best_model_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the WeightedLossTrainer for training the model.\n",
    "trainer = WeightedLossTrainer(model=model,\n",
    "                              args=training_args,\n",
    "                              train_dataset=benchmark_text_encoded['train'],\n",
    "                              eval_dataset=benchmark_text_encoded['validation'],\n",
    "                              tokenizer=tokenizer,\n",
    "                              compute_metrics= compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bf9f2032a74c4c8d48e4bc676f2468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/315 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3578, 'learning_rate': 1.9682539682539684e-05, 'epoch': 0.06}\n",
      "{'loss': 1.3775, 'learning_rate': 1.9301587301587303e-05, 'epoch': 0.11}\n",
      "{'loss': 1.2501, 'learning_rate': 1.8984126984126986e-05, 'epoch': 0.17}\n",
      "{'loss': 1.1891, 'learning_rate': 1.8603174603174605e-05, 'epoch': 0.23}\n",
      "{'loss': 1.0946, 'learning_rate': 1.8222222222222224e-05, 'epoch': 0.29}\n",
      "{'loss': 1.0213, 'learning_rate': 1.7841269841269843e-05, 'epoch': 0.34}\n",
      "{'loss': 0.9149, 'learning_rate': 1.7460317460317463e-05, 'epoch': 0.4}\n",
      "{'loss': 0.864, 'learning_rate': 1.707936507936508e-05, 'epoch': 0.46}\n",
      "{'loss': 0.7577, 'learning_rate': 1.66984126984127e-05, 'epoch': 0.51}\n",
      "{'loss': 0.7214, 'learning_rate': 1.631746031746032e-05, 'epoch': 0.57}\n",
      "{'loss': 0.5501, 'learning_rate': 1.5936507936507936e-05, 'epoch': 0.63}\n",
      "{'loss': 0.4762, 'learning_rate': 1.555555555555556e-05, 'epoch': 0.69}\n",
      "{'loss': 0.583, 'learning_rate': 1.5174603174603176e-05, 'epoch': 0.74}\n",
      "{'loss': 0.6202, 'learning_rate': 1.4793650793650795e-05, 'epoch': 0.8}\n",
      "{'loss': 0.4477, 'learning_rate': 1.4412698412698414e-05, 'epoch': 0.86}\n",
      "{'loss': 0.636, 'learning_rate': 1.4031746031746032e-05, 'epoch': 0.91}\n",
      "{'loss': 0.4064, 'learning_rate': 1.3650793650793652e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f532bcc20f094b95a2e6fd84216c3313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40253737568855286, 'eval_Accuracy': 0.8861111111111111, 'eval_F1': 0.8859683527665684, 'eval_Precision': 0.8930375197034629, 'eval_Recall': 0.8836991107348197, 'eval_runtime': 142.0429, 'eval_samples_per_second': 2.534, 'eval_steps_per_second': 0.021, 'epoch': 1.0}\n",
      "{'loss': 0.3782, 'learning_rate': 1.326984126984127e-05, 'epoch': 1.03}\n",
      "{'loss': 0.3353, 'learning_rate': 1.288888888888889e-05, 'epoch': 1.09}\n",
      "{'loss': 0.2478, 'learning_rate': 1.2507936507936508e-05, 'epoch': 1.14}\n",
      "{'loss': 0.2005, 'learning_rate': 1.2126984126984127e-05, 'epoch': 1.2}\n",
      "{'loss': 0.2064, 'learning_rate': 1.1746031746031748e-05, 'epoch': 1.26}\n",
      "{'loss': 0.4247, 'learning_rate': 1.1365079365079366e-05, 'epoch': 1.31}\n",
      "{'loss': 0.3572, 'learning_rate': 1.0984126984126986e-05, 'epoch': 1.37}\n",
      "{'loss': 0.468, 'learning_rate': 1.0603174603174604e-05, 'epoch': 1.43}\n",
      "{'loss': 0.1808, 'learning_rate': 1.0222222222222223e-05, 'epoch': 1.49}\n",
      "{'loss': 0.1702, 'learning_rate': 9.841269841269842e-06, 'epoch': 1.54}\n",
      "{'loss': 0.286, 'learning_rate': 9.460317460317461e-06, 'epoch': 1.6}\n",
      "{'loss': 0.3391, 'learning_rate': 9.07936507936508e-06, 'epoch': 1.66}\n",
      "{'loss': 0.2438, 'learning_rate': 8.6984126984127e-06, 'epoch': 1.71}\n",
      "{'loss': 0.1983, 'learning_rate': 8.317460317460319e-06, 'epoch': 1.77}\n",
      "{'loss': 0.1025, 'learning_rate': 7.936507936507936e-06, 'epoch': 1.83}\n",
      "{'loss': 0.1748, 'learning_rate': 7.555555555555556e-06, 'epoch': 1.89}\n",
      "{'loss': 0.1271, 'learning_rate': 7.174603174603175e-06, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1491, 'learning_rate': 6.7936507936507944e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4610c5df308f49659bc39dad52311c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34270069003105164, 'eval_Accuracy': 0.8972222222222223, 'eval_F1': 0.8970306001188354, 'eval_Precision': 0.9007849315846249, 'eval_Recall': 0.8953352313915589, 'eval_runtime': 147.0154, 'eval_samples_per_second': 2.449, 'eval_steps_per_second': 0.02, 'epoch': 2.0}\n",
      "{'loss': 0.0923, 'learning_rate': 6.412698412698414e-06, 'epoch': 2.06}\n",
      "{'loss': 0.0995, 'learning_rate': 6.031746031746032e-06, 'epoch': 2.11}\n",
      "{'loss': 0.1827, 'learning_rate': 5.650793650793651e-06, 'epoch': 2.17}\n",
      "{'loss': 0.2233, 'learning_rate': 5.26984126984127e-06, 'epoch': 2.23}\n",
      "{'loss': 0.0921, 'learning_rate': 4.888888888888889e-06, 'epoch': 2.29}\n",
      "{'loss': 0.0501, 'learning_rate': 4.5079365079365085e-06, 'epoch': 2.34}\n",
      "{'loss': 0.2301, 'learning_rate': 4.126984126984127e-06, 'epoch': 2.4}\n",
      "{'loss': 0.0364, 'learning_rate': 3.7460317460317463e-06, 'epoch': 2.46}\n",
      "{'loss': 0.2068, 'learning_rate': 3.3650793650793655e-06, 'epoch': 2.51}\n",
      "{'loss': 0.1457, 'learning_rate': 2.984126984126984e-06, 'epoch': 2.57}\n",
      "{'loss': 0.172, 'learning_rate': 2.6031746031746038e-06, 'epoch': 2.63}\n",
      "{'loss': 0.0387, 'learning_rate': 2.222222222222222e-06, 'epoch': 2.69}\n",
      "{'loss': 0.4029, 'learning_rate': 1.904761904761905e-06, 'epoch': 2.74}\n",
      "{'loss': 0.0375, 'learning_rate': 1.523809523809524e-06, 'epoch': 2.8}\n",
      "{'loss': 0.1628, 'learning_rate': 1.142857142857143e-06, 'epoch': 2.86}\n",
      "{'loss': 0.2007, 'learning_rate': 7.61904761904762e-07, 'epoch': 2.91}\n",
      "{'loss': 0.157, 'learning_rate': 3.80952380952381e-07, 'epoch': 2.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05433bb84c46464e8862088a2c344e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.358962744474411, 'eval_Accuracy': 0.8916666666666667, 'eval_F1': 0.8918794877027946, 'eval_Precision': 0.8954196217494089, 'eval_Recall': 0.8902409786897311, 'eval_runtime': 158.9289, 'eval_samples_per_second': 2.265, 'eval_steps_per_second': 0.019, 'epoch': 3.0}\n",
      "{'train_runtime': 4039.5725, 'train_samples_per_second': 0.624, 'train_steps_per_second': 0.078, 'train_loss': 0.4089018243172812, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=315, training_loss=0.4089018243172812, metrics={'train_runtime': 4039.5725, 'train_samples_per_second': 0.624, 'train_steps_per_second': 0.078, 'train_loss': 0.4089018243172812, 'epoch': 3.0})"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the training.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ft_bert_temuulen_tokenizer2_benchmark\\\\tokenizer_config.json',\n",
       " 'ft_bert_temuulen_tokenizer2_benchmark\\\\special_tokens_map.json',\n",
       " 'ft_bert_temuulen_tokenizer2_benchmark\\\\vocab.txt',\n",
       " 'ft_bert_temuulen_tokenizer2_benchmark\\\\added_tokens.json',\n",
       " 'ft_bert_temuulen_tokenizer2_benchmark\\\\tokenizer.json')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned BERT model.\n",
    "trainer.model.save_pretrained('ft_bert_temuulen2_benchmark')\n",
    "\n",
    "# Save the tokenizer used for fine-tuning to the 'ft_bert_temuulen3_tokenizer'.\n",
    "tokenizer.save_pretrained('ft_bert_temuulen_tokenizer2_benchmark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory paths for the fine-tuned model and tokenizer.\n",
    "model_path = 'ft_bert_temuulen2_benchmark'\n",
    "tokenizer_path = 'ft_bert_temuulen_tokenizer2_benchmark'\n",
    "\n",
    "# Load the BERT and the tokenizer.\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5c00d3749f46a8b11c14a37805df0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load prepared an unseen dataset.\n",
    "test_dataset = benchmark_text_encoded['test'] \n",
    "\n",
    "# Create a Trainer instance.\n",
    "classifier = Trainer(model=model, tokenizer=tokenizer)\n",
    "predictions = classifier.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to numpy for further analysis.\n",
    "labels = predictions.label_ids\n",
    "preds = predictions.predictions.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(23, 28, 66)"
          ],
          [
           0.09090909090909091,
           "rgb(41, 58, 143)"
          ],
          [
           0.18181818181818182,
           "rgb(11, 102, 189)"
          ],
          [
           0.2727272727272727,
           "rgb(69, 144, 185)"
          ],
          [
           0.36363636363636365,
           "rgb(142, 181, 194)"
          ],
          [
           0.45454545454545453,
           "rgb(210, 216, 219)"
          ],
          [
           0.5454545454545454,
           "rgb(230, 210, 204)"
          ],
          [
           0.6363636363636364,
           "rgb(213, 157, 137)"
          ],
          [
           0.7272727272727273,
           "rgb(196, 101, 72)"
          ],
          [
           0.8181818181818182,
           "rgb(172, 43, 36)"
          ],
          [
           0.9090909090909091,
           "rgb(120, 14, 40)"
          ],
          [
           1,
           "rgb(60, 9, 17)"
          ]
         ],
         "reversescale": false,
         "showscale": true,
         "type": "heatmap",
         "x": [
          "0",
          "1",
          "2",
          "3"
         ],
         "y": [
          "0",
          "1",
          "2",
          "3"
         ],
         "z": [
          [
           92,
           18,
           0,
           4
          ],
          [
           11,
           96,
           1,
           6
          ],
          [
           0,
           0,
           114,
           0
          ],
          [
           7,
           2,
           0,
           105
          ]
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "92",
          "x": "0",
          "xref": "x",
          "y": "0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "18",
          "x": "1",
          "xref": "x",
          "y": "0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0",
          "x": "2",
          "xref": "x",
          "y": "0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "4",
          "x": "3",
          "xref": "x",
          "y": "0",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "11",
          "x": "0",
          "xref": "x",
          "y": "1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "96",
          "x": "1",
          "xref": "x",
          "y": "1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1",
          "x": "2",
          "xref": "x",
          "y": "1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "6",
          "x": "3",
          "xref": "x",
          "y": "1",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0",
          "x": "0",
          "xref": "x",
          "y": "2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0",
          "x": "1",
          "xref": "x",
          "y": "2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "114",
          "x": "2",
          "xref": "x",
          "y": "2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0",
          "x": "3",
          "xref": "x",
          "y": "2",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "7",
          "x": "0",
          "xref": "x",
          "y": "3",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "2",
          "x": "1",
          "xref": "x",
          "y": "3",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "0",
          "x": "2",
          "xref": "x",
          "y": "3",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "105",
          "x": "3",
          "xref": "x",
          "y": "3",
          "yref": "y"
         }
        ],
        "height": 700,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "CONFUSION MATRIX: fine-tuned 'bert-base-uncased' model for classification",
         "x": 0.5
        },
        "width": 700,
        "xaxis": {
         "dtick": 1,
         "gridcolor": "rgb(0, 0, 0)",
         "side": "bottom",
         "ticks": "",
         "title": {
          "text": "Predicted Value"
         }
        },
        "yaxis": {
         "dtick": 1,
         "tickangle": -90,
         "ticks": "",
         "ticksuffix": "  ",
         "title": {
          "text": "True Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT: fine-tuned 'bert-base-uncased' model for classification \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       114\n",
      "           1       0.83      0.84      0.83       114\n",
      "           2       0.99      1.00      1.00       114\n",
      "           3       0.91      0.92      0.92       114\n",
      "\n",
      "    accuracy                           0.89       456\n",
      "   macro avg       0.89      0.89      0.89       456\n",
      "weighted avg       0.89      0.89      0.89       456\n",
      "\n",
      "{'business': 0, 'sci/tech': 1, 'sports': 2, 'world': 3}\n"
     ]
    }
   ],
   "source": [
    "# Plot Confusion Matrix.\n",
    "cm_labels = ['0', '1', '2', '3']\n",
    "cm_matrix = confusion_matrix(labels, preds)\n",
    "cm_title = \"CONFUSION MATRIX: fine-tuned 'bert-base-uncased' model for classification\"\n",
    "\n",
    "fig = ff.create_annotated_heatmap(z=cm_matrix, \n",
    "                                  x=cm_labels,\n",
    "                                  y=cm_labels, \n",
    "                                  colorscale='balance', \n",
    "                                  showscale=True,\n",
    "                                  annotation_text=cm_matrix)\n",
    "\n",
    "fig.update_layout(width=700, \n",
    "                  height=700, \n",
    "                  title=cm_title, \n",
    "                  title_x=0.5,\n",
    "                  xaxis=dict(title='Predicted Value', side='bottom'), \n",
    "                  yaxis_title='True Value')\n",
    "\n",
    "fig.update_yaxes(tickangle=-90)  \n",
    "    \n",
    "fig.show()\n",
    "\n",
    "# Print detailed classification report.\n",
    "report = classification_report(labels, preds, output_dict=True)\n",
    "report_title = \"CLASSIFICATION REPORT: fine-tuned 'bert-base-uncased' model for classification\"\n",
    "\n",
    "print(report_title, '\\n')\n",
    "print(classification_report(labels, preds))\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

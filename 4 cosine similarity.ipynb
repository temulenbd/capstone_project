{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV: COSINE SIMILARITY CALCULATION WITH DIFFERENT TEXT REPRESENTATION TECHNIQUES.\n",
    " \n",
    "This section focuses entirely on calculating the cosine similarity between the participant data and the job ads data. The calculation uses last hidden states of a fine-tuned BERT model, embeddings from a pre-trained Word2Vec model, and a combined embedding of TF-IDF with Bow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERAL\n",
    "\n",
    "- **load module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nessesary libraries.\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "import gpustat\n",
    "import warnings\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from scipy.sparse import hstack\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **check computational environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINDOWS VERSION: Windows-10-10.0.22631-SP0\n",
      "PYTHON VERSION: 3.11.4 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 13:38:37) [MSC v.1916 64 bit (AMD64)]\n",
      "CPU CORE: 4\n",
      "CPU SPEED: scpufreq(current=2496.0, min=0.0, max=2496.0)\n",
      "GPU: NVIDIA GeForce GTX 1650\n",
      "RAM: 31.87 GB\n",
      "HARD DRIVE: 237.45 GB\n"
     ]
    }
   ],
   "source": [
    "# List the software and hardware configurations used for conducting the experiment.\n",
    "print('WINDOWS VERSION:', platform.platform())\n",
    "print('PYTHON VERSION:', sys.version)\n",
    "print('CPU CORE:', psutil.cpu_count(logical=False))\n",
    "print('CPU SPEED:', psutil.cpu_freq())\n",
    "print('GPU:', gpustat.new_query().gpus[0].name)\n",
    "print(f'RAM: {psutil.virtual_memory().total/(1024 ** 3):.2f} GB')\n",
    "print(f\"HARD DRIVE: {psutil.disk_usage('/').total/(1024 ** 3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **load dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*job seekers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the joob seekers' data frame is: (3, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>data_collection</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>preferred_position</th>\n",
       "      <th>education</th>\n",
       "      <th>skill</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-17 15:30:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>registered nurse</td>\n",
       "      <td>bachelor's degree: critical care nursing</td>\n",
       "      <td>patient care, wound care, medical procedures, ...</td>\n",
       "      <td>registered nurse: 3 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-27 11:50:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>electrician</td>\n",
       "      <td>high school diploma, vocational electrician ce...</td>\n",
       "      <td>circuit testing, blueprint reading, fault find...</td>\n",
       "      <td>residential electrician's helper: 1 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_3</td>\n",
       "      <td>google form</td>\n",
       "      <td>2023-12-31 13:39:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>degree: master of science in data analytics, b...</td>\n",
       "      <td>python, data mining and extraction, data analy...</td>\n",
       "      <td>entry level data analyst: 1 year; data coordin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant data_collection                 date         location  \\\n",
       "0      user_1      voice call  2023-12-17 15:30:00  dublin, ireland   \n",
       "1      user_2      voice call  2023-12-27 11:50:00  dublin, ireland   \n",
       "2      user_3     google form  2023-12-31 13:39:00  dublin, ireland   \n",
       "\n",
       "  preferred_position                                          education  \\\n",
       "0   registered nurse           bachelor's degree: critical care nursing   \n",
       "1        electrician  high school diploma, vocational electrician ce...   \n",
       "2       data analyst  degree: master of science in data analytics, b...   \n",
       "\n",
       "                                               skill  \\\n",
       "0  patient care, wound care, medical procedures, ...   \n",
       "1  circuit testing, blueprint reading, fault find...   \n",
       "2  python, data mining and extraction, data analy...   \n",
       "\n",
       "                                          experience  \n",
       "0                          registered nurse: 3 years  \n",
       "1           residential electrician's helper: 1 year  \n",
       "2  entry level data analyst: 1 year; data coordin...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the experiment participants dataset.\n",
    "df_jobseeker = pd.read_csv('data_jobseeker.csv', index_col=None)\n",
    "print(\"The shape of the joob seekers' data frame is:\", df_jobseeker.shape)\n",
    "\n",
    "df_jobseeker.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset consists of 3 rows and 8 columns of data collected from experiment participants through interviews. The last three columns in this DataFrame (DF), which contain text data on education, skill, and experience, are intended to be used for analysis. Calculating the cosine score for each column individually is impractical and illogical. Therefore, it is necessary to combine these columns into a single one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>data_collection</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>preferred_position</th>\n",
       "      <th>combined_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-17 15:30:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>registered nurse</td>\n",
       "      <td>bachelor's degree: critical care nursing. pati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-27 11:50:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>electrician</td>\n",
       "      <td>high school diploma, vocational electrician ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_3</td>\n",
       "      <td>google form</td>\n",
       "      <td>2023-12-31 13:39:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>degree: master of science in data analytics, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant data_collection                 date         location  \\\n",
       "0      user_1      voice call  2023-12-17 15:30:00  dublin, ireland   \n",
       "1      user_2      voice call  2023-12-27 11:50:00  dublin, ireland   \n",
       "2      user_3     google form  2023-12-31 13:39:00  dublin, ireland   \n",
       "\n",
       "  preferred_position                                      combined_info  \n",
       "0   registered nurse  bachelor's degree: critical care nursing. pati...  \n",
       "1        electrician  high school diploma, vocational electrician ce...  \n",
       "2       data analyst  degree: master of science in data analytics, b...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply minor modifications for further use.\n",
    "df_jobseeker['combined_info'] = df_jobseeker.education + '. ' + df_jobseeker.skill + '. ' + df_jobseeker.experience + '.'\n",
    "df_jobseeker.drop(['education', 'skill', 'experience'], axis=1, inplace=True)\n",
    "\n",
    "df_jobseeker.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having merged the text data into a single column, it is essential to perform a word count. This step will guide us in determining the appropriate approach for processing this text in the subsequent analytical stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>data_collection</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>preferred_position</th>\n",
       "      <th>combined_info</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-17 15:30:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>registered nurse</td>\n",
       "      <td>bachelor's degree: critical care nursing. pati...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-27 11:50:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>electrician</td>\n",
       "      <td>high school diploma, vocational electrician ce...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_3</td>\n",
       "      <td>google form</td>\n",
       "      <td>2023-12-31 13:39:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>degree: master of science in data analytics, b...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant data_collection                 date         location  \\\n",
       "0      user_1      voice call  2023-12-17 15:30:00  dublin, ireland   \n",
       "1      user_2      voice call  2023-12-27 11:50:00  dublin, ireland   \n",
       "2      user_3     google form  2023-12-31 13:39:00  dublin, ireland   \n",
       "\n",
       "  preferred_position                                      combined_info  \\\n",
       "0   registered nurse  bachelor's degree: critical care nursing. pati...   \n",
       "1        electrician  high school diploma, vocational electrician ce...   \n",
       "2       data analyst  degree: master of science in data analytics, b...   \n",
       "\n",
       "   word_count  \n",
       "0          27  \n",
       "1          33  \n",
       "2          60  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the word count for each ad and add its values to a new column.\n",
    "df_jobseeker['word_count'] = df_jobseeker['combined_info'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df_jobseeker.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*job ads*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the joob ads' data frame is: (1166, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical nurse manager (cnm)</td>\n",
       "      <td>sj_358f1f68cde928c4</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>registered nurse</td>\n",
       "      <td>job_4e16e9830b072344</td>\n",
       "      <td>https://ie.indeed.com/rc/clk?jk=4e16e9830b0723...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>access healthcare, one of irelands leading hea...</td>\n",
       "      <td>registered_nurse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                    id  \\\n",
       "0  assistant director of nursing   sj_3c7e64c7996bb9d6   \n",
       "1   clinical nurse manager (cnm)   sj_358f1f68cde928c4   \n",
       "2               registered nurse  job_4e16e9830b072344   \n",
       "\n",
       "                                                link              date  \\\n",
       "0  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "1  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...           unknown   \n",
       "2  https://ie.indeed.com/rc/clk?jk=4e16e9830b0723...  January 10, 2024   \n",
       "\n",
       "                                     job_description             label  \n",
       "0  silver stream healthcare group offer great emp...  registered_nurse  \n",
       "1  create a better future for yourself  recruitne...  registered_nurse  \n",
       "2  access healthcare, one of irelands leading hea...  registered_nurse  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the online job ads dataset and apply minor modifications for further use.\n",
    "df_jobads = pd.read_csv('data_jobads_final.csv', index_col=None)\n",
    "df_jobads['job_description'] = df_jobads['job_description'].str.replace('\\n', ' ')\n",
    "df_jobads = df_jobads.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"The shape of the joob ads' data frame is:\", df_jobads.shape)\n",
    "df_jobads.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second dataset consists of 1166 rows and 6 columns of data scraped from Indeed.com. The most essential column in this DF is the one with job descriptions. Similarly to the first DF, counting the words for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical nurse manager (cnm)</td>\n",
       "      <td>sj_358f1f68cde928c4</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>registered nurse</td>\n",
       "      <td>job_4e16e9830b072344</td>\n",
       "      <td>https://ie.indeed.com/rc/clk?jk=4e16e9830b0723...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>access healthcare, one of irelands leading hea...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                    id  \\\n",
       "0  assistant director of nursing   sj_3c7e64c7996bb9d6   \n",
       "1   clinical nurse manager (cnm)   sj_358f1f68cde928c4   \n",
       "2               registered nurse  job_4e16e9830b072344   \n",
       "\n",
       "                                                link              date  \\\n",
       "0  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "1  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...           unknown   \n",
       "2  https://ie.indeed.com/rc/clk?jk=4e16e9830b0723...  January 10, 2024   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "1  create a better future for yourself  recruitne...  registered_nurse   \n",
       "2  access healthcare, one of irelands leading hea...  registered_nurse   \n",
       "\n",
       "   word_count  \n",
       "0         502  \n",
       "1         231  \n",
       "2         182  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobads['word_count'] = df_jobads['job_description'].apply(lambda x: len(x.split()))\n",
    "df_jobads.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All necessary libraries have been imported, and the datasets are also laoded and ready for use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. WITH FINE-TUNED BERT MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sub-section, the text columns from both DFs are fed into Bert's fine-tuned encoding layers, and the resulting text representations from the last hidden layer are collected for cosine similarity computation. For demonstration purposes lets run the test for only one row value and retrieve the final hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  5065,  1005,  1055,  3014,  1024,  4187,  2729,  8329,  1012,\n",
      "          5776,  2729,  1010,  6357,  2729,  1010,  2966,  8853,  1010,  4639,\n",
      "          8329,  1010,  8985,  2491,  1010, 16474,  1010,  2051,  2968,  1010,\n",
      "          4807,  4813,  1010,  3086,  2000,  6987,  1012,  5068,  6821,  1024,\n",
      "          1017,  2086,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# Assigning the text for demonstration to a variable.\n",
    "input_text_test = df_jobseeker.iat[0, -2]\n",
    "\n",
    "# Initialize a fine-tuned model with the hidden state output enabled.\n",
    "model = BertForSequenceClassification.from_pretrained('ft_bert_temuulen2', output_hidden_states=True)\n",
    "\n",
    "# Initialize a tokenizer used for the fine-tuned model.\n",
    "tokenizer = AutoTokenizer.from_pretrained('ft_bert_temuulen_tokenizer2')\n",
    "\n",
    "# Tokenize the input text and convert it to PyTorch tensors.\n",
    "inputs = tokenizer(input_text_test, return_tensors='pt')\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous cell, the test text specified for demonstration purposes was assigned to a variable and tokenized. The results were formatted as tensors to be compatible with our deep learning framework, PyTorch in this instance. The output of the cell shows that input itself consists of **input_ids** and **attention_mask** values, which are important for further procesing, as well as **token_type_ids** values, which are optional for the current context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the last hidden state tensor is: torch.Size([1, 44, 768]) \n",
      "\n",
      "The data type of the last hidden state tensor is: <class 'torch.Tensor'> \n",
      "\n",
      "tensor([[[-0.0363,  0.2450,  0.5963,  ...,  0.3683, -0.0280, -0.8850],\n",
      "         [ 0.2678,  0.2943,  0.7582,  ...,  0.6081,  0.3891, -0.7876],\n",
      "         [ 0.6730,  0.5588,  0.0457,  ...,  0.3886, -0.1934, -0.3093],\n",
      "         ...,\n",
      "         [ 0.2063,  1.2522,  0.8961,  ...,  0.4514, -0.2191, -0.9838],\n",
      "         [-0.4627,  0.0477,  0.2985,  ...,  1.0643, -0.1532, -0.7737],\n",
      "         [ 0.6308,  0.5534,  0.1932,  ...,  0.4055, -0.1966, -0.3423]]])\n"
     ]
    }
   ],
   "source": [
    "# Perform a forward pass through the model to get the hidden states.\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract the last hidden states from the model outputs.\n",
    "last_hidden_states = outputs.hidden_states[-1]\n",
    "\n",
    "print('The size of the last hidden state tensor is:', last_hidden_states.shape, '\\n')\n",
    "print('The data type of the last hidden state tensor is:', type(last_hidden_states), '\\n')\n",
    "print(last_hidden_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following tokenization, the input values were passed forward through the model, resulting in the extraction of a torch tensor representing hidden states with dimensions of ([1, 44, 768]). This tensor will then be used for cosine similarity calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Experiment\n",
    "\n",
    "The test demonstration went well and the tensor was successfully extracted. Now lets begin the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the timer to track the execution duration.\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialize model*\n",
    "\n",
    "The encoding model has been fine-tuned using the **bert-based-uncased** architecture for text sequence classification and was imported from the personal drive. The tokenizer employed is HuggingFace's autotokenizer, which automatically selects and pairs with the most suitable tokenizer for the model. In this instance, it is the **BertTokenizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a fine-tuned model with the hidden state output enabled.\n",
    "model = BertForSequenceClassification.from_pretrained('ft_bert_temuulen2', output_hidden_states=True)\n",
    "\n",
    "# Initialize a tokenizer used for the fine-tuned model.\n",
    "tokenizer = AutoTokenizer.from_pretrained('ft_bert_temuulen_tokenizer2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*load dataset*\n",
    "\n",
    "The dataset used in this implementation is a duplicate of the primary DFs containing information about job seekers and job advertisements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets.\n",
    "df_bert_js = df_jobseeker.copy()\n",
    "df_bert_ja = df_jobads.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialize gpu* (optional)\n",
    "\n",
    "To enhance the effectiveness of managing matrix and tensor operations, the CUDA device was created. This capability represents a key advantage of utilizing the BERT model within the Torch framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA was successfully installed and compiled on my device.\n",
      "CUDA device name is: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "# Check whether CUDA is accessible and, if so, create a CUDA device.\n",
    "cuda_available = torch.cuda.is_available()\n",
    "cuda_device= torch.cuda.get_device_name(0)\n",
    "\n",
    "if cuda_available == True:\n",
    "    device = torch.device('cuda')\n",
    "    print('CUDA was successfully installed and compiled on my device.')\n",
    "    print('CUDA device name is:', cuda_device)\n",
    "else:\n",
    "    print('Cuda in not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the encoding process, it's essential to check the word count to ensure that it doesn't surpass 510, due to a constraint associated with the BERT model. If the word count exceed this threshold, it is necessary to formulate a new strategy for obtaining the encoded value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of rows having word counts greater than 510 in the first DF is: 0\n",
      "The total number of rows having word counts greater than 510 in the second DF is: 236\n",
      "The word count for the longest text is: 3145\n"
     ]
    }
   ],
   "source": [
    "print('The total number of rows having word counts greater than 510 in the first DF is:', df_bert_js[df_bert_js['word_count'] > 510].shape[0])\n",
    "print('The total number of rows having word counts greater than 510 in the second DF is:', df_bert_ja[df_bert_ja['word_count'] > 510].shape[0])\n",
    "print('The word count for the longest text is:', df_bert_ja.iat[df_bert_ja['word_count'].idxmax(), -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*create custom function*\n",
    "\n",
    "From the output observed in the preceding cell, it is clear that the DF for job seekers does not contain entries exceeding the 510-word limit, allowing the definition of a standard custom function for tokenization and extraction of the last hidden state without additional conditions. Conversely, the DF for job advertisements contains 236 entries surpassing the 510-word threshold, with the longest text totaling 3145 words. To process these inputs through the model, a custom function incorporating special conditions must be developed and applied. The upcoming two custom functions are designed specifically for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to extract the final layer encodings from BERT, without conditions.\n",
    "def process_text(text):\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    \n",
    "    # Pass the tokenized input through the model.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Retrieve the last hidden states from the model's outputs.\n",
    "    last_hidden_states = outputs.hidden_states[-1]\n",
    "    \n",
    "    return last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to extract the final layer encodings from BERT, with conditions.\n",
    "def embed_with_bert(df_column):\n",
    "    \n",
    "    embedded_texts = []\n",
    "    \n",
    "    # Iterate through each text in the DataFrame column.\n",
    "    for text in df_column:\n",
    "        \n",
    "        # Tokenize each text without adding special tokens and without truncation or padding.\n",
    "        tokens = tokenizer(text, add_special_tokens=False, return_tensors='pt', truncation=False, padding=False)['input_ids'].squeeze()\n",
    "        token_length = len(tokens)\n",
    "        \n",
    "        # If the token length is less than or equal to 512, process it normally.\n",
    "        if token_length <= 512:\n",
    "            inputs = tokenizer(text, return_tensors='pt').to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "            last_hidden_states = outputs.hidden_states[-1].cpu()  \n",
    "            embedded_texts.append(last_hidden_states)\n",
    "            \n",
    "        # If the token length is greater than 512, split it into sliding windows withot lapping.\n",
    "        else:\n",
    "            max_length = 512\n",
    "            stride = 0\n",
    "            tokens = tokenizer(text, add_special_tokens=False, return_tensors='pt', truncation=False, padding=False)['input_ids'].squeeze().to(device)\n",
    "            token_windows = [tokens[i:i+max_length] for i in range(0, len(tokens), max_length - stride)]\n",
    "            \n",
    "            all_hidden_states = []\n",
    "            \n",
    "            # Add special tokens (CLS and SEP) and truncate if needed.\n",
    "            for window in token_windows:\n",
    "                window = torch.cat([torch.tensor([tokenizer.cls_token_id], device=device), window, torch.tensor([tokenizer.sep_token_id], device=device)])\n",
    "                if len(window) > max_length:\n",
    "                    window = torch.cat((window[:max_length-1], torch.tensor([tokenizer.sep_token_id], device=device)))\n",
    "                inputs = {'input_ids': window.unsqueeze(0)}\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                hidden_states = outputs.hidden_states[-1].cpu()  \n",
    "                all_hidden_states.append(hidden_states)\n",
    "            \n",
    "            # Concatenate all hidden states from each sliding window.\n",
    "            embedded_texts.append(torch.cat(all_hidden_states, dim=1))\n",
    "            \n",
    "    return embedded_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Furthermore, as observed in the previous test demonstration, the text that passes through the encoders generates a hidden states tensor with three dimensions. To keep the textual information without aggregating these dimensions, it is necessary to define a custom function. The function below processes the tensor of a user's text, computes the cosine score for each pair, and then returns the average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a costum function that generates the evarage cosine similarity between the user's tensor and a job ad's tensor.\n",
    "def calculate_average_similarity(tensor_user, tensor_ad):\n",
    "    \n",
    "    # Squeeze dimensions if the tensors have a batch dimension.\n",
    "    tensor_user = tensor_user.squeeze(0) if tensor_user.dim() == 3 else tensor_user\n",
    "    tensor_ad = tensor_ad.squeeze(0) if tensor_ad.dim() == 3 else tensor_ad\n",
    "\n",
    "    tensor_ad = tensor_ad.to(tensor_user.device)\n",
    "\n",
    "    # Initialize a similarity matrix with zeros.\n",
    "    similarity_matrix = torch.zeros(tensor_user.size(0), tensor_ad.size(0), device=tensor_user.device)\n",
    "    \n",
    "    # Calculate cosine similarity for each pair of vectors.\n",
    "    for i in range(tensor_user.size(0)):\n",
    "        for j in range(tensor_ad.size(0)):\n",
    "            similarity_matrix[i, j] = F.cosine_similarity(tensor_user[i].unsqueeze(0), tensor_ad[j].unsqueeze(0), dim=1)\n",
    "            \n",
    "    # Calculate the average similarity and convert it to a Python float.\n",
    "    average_similarity = torch.mean(similarity_matrix).item()\n",
    "    \n",
    "    return average_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*encode text*\n",
    "\n",
    "Using the custom functions created earlier to process each DF and extract the tensor of the final hidden state layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the first tensor: torch.Size([1, 44, 768]) \n",
      "\n",
      "The shape of the second tensor: torch.Size([1, 60, 768]) \n",
      "\n",
      "The shape of the third tensor: torch.Size([1, 89, 768]) \n",
      "\n",
      "tensor([[[-0.0363,  0.2450,  0.5963,  ...,  0.3683, -0.0280, -0.8850],\n",
      "         [ 0.2678,  0.2943,  0.7582,  ...,  0.6081,  0.3891, -0.7876],\n",
      "         [ 0.6730,  0.5588,  0.0457,  ...,  0.3886, -0.1934, -0.3093],\n",
      "         ...,\n",
      "         [ 0.2063,  1.2522,  0.8961,  ...,  0.4514, -0.2191, -0.9838],\n",
      "         [-0.4627,  0.0477,  0.2985,  ...,  1.0643, -0.1532, -0.7737],\n",
      "         [ 0.6308,  0.5534,  0.1932,  ...,  0.4055, -0.1966, -0.3423]]]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>data_collection</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>preferred_position</th>\n",
       "      <th>combined_info</th>\n",
       "      <th>word_count</th>\n",
       "      <th>last_layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-17 15:30:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>registered nurse</td>\n",
       "      <td>bachelor's degree: critical care nursing. pati...</td>\n",
       "      <td>27</td>\n",
       "      <td>[[[tensor(-0.0363), tensor(0.2450), tensor(0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-27 11:50:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>electrician</td>\n",
       "      <td>high school diploma, vocational electrician ce...</td>\n",
       "      <td>33</td>\n",
       "      <td>[[[tensor(-0.0979), tensor(-0.6441), tensor(0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_3</td>\n",
       "      <td>google form</td>\n",
       "      <td>2023-12-31 13:39:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>data analyst</td>\n",
       "      <td>degree: master of science in data analytics, b...</td>\n",
       "      <td>60</td>\n",
       "      <td>[[[tensor(-0.4467), tensor(0.4116), tensor(-0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant data_collection                 date         location  \\\n",
       "0      user_1      voice call  2023-12-17 15:30:00  dublin, ireland   \n",
       "1      user_2      voice call  2023-12-27 11:50:00  dublin, ireland   \n",
       "2      user_3     google form  2023-12-31 13:39:00  dublin, ireland   \n",
       "\n",
       "  preferred_position                                      combined_info  \\\n",
       "0   registered nurse  bachelor's degree: critical care nursing. pati...   \n",
       "1        electrician  high school diploma, vocational electrician ce...   \n",
       "2       data analyst  degree: master of science in data analytics, b...   \n",
       "\n",
       "   word_count                                         last_layer  \n",
       "0          27  [[[tensor(-0.0363), tensor(0.2450), tensor(0.5...  \n",
       "1          33  [[[tensor(-0.0979), tensor(-0.6441), tensor(0....  \n",
       "2          60  [[[tensor(-0.4467), tensor(0.4116), tensor(-0....  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function and create a new column with the extracted results.\n",
    "df_bert_js['last_layer'] = df_bert_js.iloc[:, -2].apply(process_text)\n",
    "\n",
    "print('The shape of the first tensor:', df_bert_js.iat[0, -1].shape, '\\n')\n",
    "print('The shape of the second tensor:', df_bert_js.iat[1, -1].shape, '\\n')\n",
    "print('The shape of the third tensor:', df_bert_js.iat[2, -1].shape, '\\n')\n",
    "print(df_bert_js.iat[0, -1], '\\n')\n",
    "\n",
    "# Check the Data Frame.\n",
    "df_bert_js.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 617, 768]) \n",
      "\n",
      "tensor([[[-0.2150,  0.5150,  0.9837,  ...,  0.3223,  0.1705, -0.9307],\n",
      "         [ 0.4196,  0.1590,  0.8688,  ...,  0.7425,  0.5898, -0.4012],\n",
      "         [ 0.0512,  0.1291,  1.1575,  ...,  0.5806,  0.6952, -0.7819],\n",
      "         ...,\n",
      "         [ 0.3018,  0.2411,  0.6686,  ...,  0.8269,  0.3707,  0.1042],\n",
      "         [ 0.1389,  1.0224,  0.7068,  ...,  0.7878, -0.0621, -0.2271],\n",
      "         [ 0.5809,  1.0120,  0.4087,  ...,  0.9232,  0.4165, -0.5864]]]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>tensors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "      <td>[[[tensor(-0.2150), tensor(0.5150), tensor(0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical nurse manager (cnm)</td>\n",
       "      <td>sj_358f1f68cde928c4</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>231</td>\n",
       "      <td>[[[tensor(-0.0909), tensor(0.6022), tensor(0.9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "1   clinical nurse manager (cnm)  sj_358f1f68cde928c4   \n",
       "\n",
       "                                                link              date  \\\n",
       "0  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "1  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...           unknown   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "1  create a better future for yourself  recruitne...  registered_nurse   \n",
       "\n",
       "   word_count                                            tensors  \n",
       "0         502  [[[tensor(-0.2150), tensor(0.5150), tensor(0.9...  \n",
       "1         231  [[[tensor(-0.0909), tensor(0.6022), tensor(0.9...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to the GPU.\n",
    "model.to(device)\n",
    "\n",
    "# Apply the 'embed_with_bert' function to each ad.\n",
    "df_bert_ja['tensors'] = df_bert_ja['job_description'].apply(lambda x: embed_with_bert([x])[0])\n",
    "\n",
    "# Check the random cell to see the results.\n",
    "print(df_bert_ja.iat[0, -1].shape, '\\n')\n",
    "print(df_bert_ja.iat[0, -1], '\\n')\n",
    "\n",
    "# Check the Data Frame.\n",
    "df_bert_ja.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from the previous cells indicate that the tensors generated by processing each text entry from the 'combined_info' column through the encoding layers of the fine-tuned models maintain consistent dimensions in the first and third positions. This consistency is due to the fact that each encoder handles a single sample at a time, with a batch size of one, and represents each token in the text with a 768-feature vector. However, the number of tokens in the second dimensions, representing each text, varies and slightly exceeds the actual word count of each text. This variability is because of the WordPiece tokenization approach used by the BERT model, which breaks down words into smaller pieces if they are not present in the tokenizer's lexicon. This approach enables the model to more effectively manage unrecognized words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*calculate cosine*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the texts from user1 and user2 is: -0.045444291085004807\n"
     ]
    }
   ],
   "source": [
    "print('The cosine similarity between the texts from user1 and user2 is:', calculate_average_similarity(df_bert_js.iat[0, -1], df_bert_js.iat[1, -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin the calculation, let's evaluate the cosine similarity between the tensors of two participants. Observing from the previous cell, the outcome is negative, which is expected considering the first participant is interested in registered nurse positions, whereas the second is seeking opportunities as an electrician. Next, we will proceed to apply the custom function across the entire dataframes to compute the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign User's tensors to variables and then move them to a GPU for processing with PyTorch.\n",
    "user1_tensor = df_bert_js.iat[0, -1]\n",
    "user1_tensor = user1_tensor.to(device)\n",
    "\n",
    "user2_tensor = df_bert_js.iat[1, -1]\n",
    "user2_tensor = user2_tensor.to(device)\n",
    "\n",
    "user3_tensor = df_bert_js.iat[2, -1]\n",
    "user3_tensor = user3_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the calculation of average cosine similarity function to each job ad's tensor.\n",
    "df_bert_ja['cos_user1'] = df_bert_ja.iloc[:, -1].apply(lambda x: calculate_average_similarity(user1_tensor, x.to(device)))\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "df_bert_ja['cos_user2'] = df_bert_ja.iloc[:, -2].apply(lambda x: calculate_average_similarity(user2_tensor, x.to(device)))\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "df_bert_ja['cos_user3'] = df_bert_ja.iloc[:, -3].apply(lambda x: calculate_average_similarity(user3_tensor, x.to(device)))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cos_user1</th>\n",
       "      <th>cos_user2</th>\n",
       "      <th>cos_user3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "      <td>0.644372</td>\n",
       "      <td>-0.061539</td>\n",
       "      <td>-0.079645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical nurse manager (cnm)</td>\n",
       "      <td>sj_358f1f68cde928c4</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>231</td>\n",
       "      <td>0.654735</td>\n",
       "      <td>-0.091259</td>\n",
       "      <td>-0.054981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "1   clinical nurse manager (cnm)  sj_358f1f68cde928c4   \n",
       "\n",
       "                                                link              date  \\\n",
       "0  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "1  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...           unknown   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "1  create a better future for yourself  recruitne...  registered_nurse   \n",
       "\n",
       "   word_count  cos_user1  cos_user2  cos_user3  \n",
       "0         502   0.644372  -0.061539  -0.079645  \n",
       "1         231   0.654735  -0.091259  -0.054981  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the encoded column from the Data Frame (it takes up too much memory and is no longer needed).\n",
    "df_bert_ja = df_bert_ja.drop(columns=['tensors']) \n",
    "\n",
    "# Save the DF to local drive.\n",
    "df_bert_ja.to_csv('cosine_bert.csv', index=False)\n",
    "\n",
    "df_bert_ja.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine similarity scores were calculated for each user, and the resulting DF, now including the cosine similarity results, has been saved locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculation of cosine similarity score using fine-tuned Bert model completed in: 373 minutes and 54 seconds.\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(f'The calculation of cosine similarity score using fine-tuned Bert model completed in: {int((end - start)) // 60} minutes and {int((end - start)) % 60} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. WITH PRE-TRAINED WORD2VEC\n",
    "\n",
    "In this sub-section text of each DF is passes throuth the choosen Word2Vec model as an input and generates the everage of all the word vectors as a single embedding vector. Then, these vectors are compared for cosine similarity with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the timer to track the execution duration.\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialize model*\n",
    "\n",
    "The pre-trained GoogleNews-vectors-negative300 model from Google is used for embedding. This model is trained on a dataset including approximately 100 billion words from Google News and features 300-dimensional vectors for 3 million words and phrases, therefore, it's widely used for various natural language processing (NLP) tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Word2Vec model\n",
    "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*load dataset*\n",
    "\n",
    "As for the datasets, dublicates of the primary DFs are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets.\n",
    "df_word2vec_js = df_jobseeker.copy()\n",
    "df_word2vec_ja = df_jobads.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*create custom function*\n",
    "\n",
    "The preprocessing and tokenization steps for Word2Vec differ from those of transformer models, as Word2Vec exclusively uses whole words to generate embeddings and its fixed token limit for the input is 10000. Every word in this model has a fixed vector value, making it easier to derive embeddings using aggregation methods. And the following custom functions have been defined to accommodate these specific characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a costum function for preprocessing and tokenizing the text.\n",
    "def preprocess_text_word2vec(text):\n",
    "    # Lowercasing.\n",
    "    text = text.lower()\n",
    "    # Removing punctuation.\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Tokenization.\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a costum function that returns an embedding vector.\n",
    "def embed_tokens(tokens_list, model):\n",
    "    # Iterate through each token in the list\n",
    "    vectors = [model[word] for word in tokens_list if word in model]\n",
    "    if vectors:\n",
    "        # Averaging the vectors.\n",
    "        embedding = np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        # Use a zero vector if none of the tokens were found in the Word2Vec model.\n",
    "        embedding = np.zeros(model.vector_size)\n",
    "        \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following preprocessing and tokenization with the next custom function, each input's embedded vectors can be compared pairwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate cosine similarity (dot product in this case)\n",
    "def cos(vector1, vector2):\n",
    "    return np.dot(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*preprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>data_collection</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>preferred_position</th>\n",
       "      <th>combined_info</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-17 15:30:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>registered nurse</td>\n",
       "      <td>bachelor's degree: critical care nursing. pati...</td>\n",
       "      <td>27</td>\n",
       "      <td>[bachelors, degree, critical, care, nursing, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-27 11:50:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>electrician</td>\n",
       "      <td>high school diploma, vocational electrician ce...</td>\n",
       "      <td>33</td>\n",
       "      <td>[high, school, diploma, vocational, electricia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant data_collection                 date         location  \\\n",
       "0      user_1      voice call  2023-12-17 15:30:00  dublin, ireland   \n",
       "1      user_2      voice call  2023-12-27 11:50:00  dublin, ireland   \n",
       "\n",
       "  preferred_position                                      combined_info  \\\n",
       "0   registered nurse  bachelor's degree: critical care nursing. pati...   \n",
       "1        electrician  high school diploma, vocational electrician ce...   \n",
       "\n",
       "   word_count                                       processed_ci  \n",
       "0          27  [bachelors, degree, critical, care, nursing, p...  \n",
       "1          33  [high, school, diploma, vocational, electricia...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to preprocess the input text.\n",
    "df_word2vec_js['processed_ci'] = df_word2vec_js['combined_info'].apply(preprocess_text_word2vec)\n",
    "df_word2vec_ja['processed_jd'] = df_word2vec_ja['job_description'].apply(preprocess_text_word2vec)\n",
    "\n",
    "df_word2vec_js.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*embedding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the first random vector is: (300,) \n",
      "\n",
      "The shape of the second random vector is: (300,) \n",
      "\n",
      "[-6.08450100e-02  6.02449253e-02 -1.20016243e-02  7.13876588e-03\n",
      " -7.40720332e-02  4.22175489e-02  1.12180419e-01 -1.45709693e-01\n",
      "  1.79331861e-02 -1.19441107e-01 -4.40439060e-02 -9.83276367e-02\n",
      "  1.14898682e-02  1.12257734e-01 -4.97694761e-02  2.10800171e-02\n",
      "  2.50693094e-02  1.47782549e-01 -1.60428565e-02 -4.22304608e-02\n",
      "  5.18317595e-02 -4.93539646e-02  9.00793448e-02  5.93214780e-02\n",
      " -7.79548055e-03  1.60757210e-02 -1.52020961e-01  2.08504014e-02\n",
      "  9.60305985e-03 -1.08370267e-01 -4.76262011e-02 -1.63949821e-02\n",
      " -6.17863573e-02 -8.93061683e-02 -9.40270051e-02 -2.90926415e-02\n",
      "  9.55681428e-02  4.57352847e-02  2.02589761e-03  2.31417138e-02\n",
      " -1.01036662e-02 -2.45408285e-02 -4.26882245e-02  4.94384766e-03\n",
      " -5.06456830e-02 -1.39112025e-01  4.37387303e-02  8.94681513e-02\n",
      " -2.47074999e-02  3.91387939e-02 -8.30829293e-02 -1.72072183e-02\n",
      " -2.95879655e-02 -1.32446289e-02 -3.79685611e-02  2.60244515e-02\n",
      "  1.91732554e-03  3.87948826e-02 -3.33838835e-02 -3.83711606e-02\n",
      " -6.47043064e-02  4.48628925e-02  2.36393847e-02 -1.29410967e-01\n",
      "  6.06610961e-02  1.23652533e-01 -4.82433029e-02  1.26117408e-01\n",
      " -4.93956357e-02 -4.24992479e-02  8.89117923e-03  1.10051082e-02\n",
      "  1.12215482e-01 -3.25786881e-02 -8.13340396e-02  1.59424997e-03\n",
      "  4.10012454e-02 -1.86620858e-02  1.06344372e-01  1.80031404e-01\n",
      "  1.31595321e-02  1.96674056e-02  4.12257276e-02  4.84337434e-02\n",
      "  1.73069886e-03 -3.42759341e-02 -9.88217890e-02  1.24080949e-01\n",
      "  2.17731181e-03 -8.68812017e-03  1.80457488e-01 -4.74665733e-03\n",
      " -3.00624557e-02 -2.93276869e-02  6.01736233e-02 -6.12429120e-02\n",
      "  1.35526210e-01 -1.91157423e-02 -1.35920593e-03 -9.53909103e-03\n",
      "  2.51723062e-02 -1.29583508e-01 -2.07190886e-02 -8.07870701e-02\n",
      "  2.74118278e-02 -1.38352618e-01  2.61124838e-02  3.87719972e-03\n",
      "  1.20756879e-01 -8.30794126e-02  2.34850366e-02  5.79998307e-02\n",
      " -7.77887180e-02 -7.19510578e-03 -1.59935579e-02  5.52227311e-02\n",
      " -6.26784109e-04 -8.34867060e-02  9.69138518e-02  2.82757096e-02\n",
      " -2.67925560e-01 -1.45967919e-02 -3.07617188e-02  4.93915286e-03\n",
      "  1.21043277e-05  2.39210855e-03 -1.68550927e-02 -5.17801121e-02\n",
      "  9.64731053e-02  1.40336111e-01 -1.43004935e-02 -1.01355918e-01\n",
      " -1.17387041e-01 -5.84976487e-02 -2.89024934e-02 -6.89914376e-02\n",
      " -4.43443879e-02  7.73268472e-03 -1.53151294e-02  8.43212456e-02\n",
      "  4.41771280e-03 -1.96533203e-02  2.81919707e-02  1.07546588e-02\n",
      " -6.14224933e-02  3.46444920e-02  3.07945833e-02  8.37414116e-02\n",
      " -1.57502398e-01 -5.06685711e-02  1.38946533e-01  8.41416568e-02\n",
      " -4.61284928e-02  4.79830243e-02 -3.50205004e-02 -1.00886419e-01\n",
      " -4.64814976e-02 -4.67576236e-02 -4.41331118e-02 -9.26818848e-02\n",
      "  2.29222216e-02  1.16753943e-01 -2.56934529e-03  8.48400444e-02\n",
      " -1.32305443e-01 -1.13108708e-02 -5.15136719e-02 -1.12828329e-01\n",
      "  1.60088167e-02 -1.38282195e-01  1.78052466e-02 -2.16774568e-02\n",
      " -6.26279414e-02 -1.02516763e-01  2.96466537e-02 -8.35526455e-03\n",
      "  8.14443752e-02 -5.67415692e-02 -7.72916377e-02 -4.13231477e-02\n",
      " -9.04799253e-02 -5.13939485e-02  5.63455746e-02 -5.84458560e-02\n",
      " -4.93615940e-02  2.45959945e-02 -1.23968860e-02 -1.10332780e-02\n",
      "  5.87345995e-02 -5.41334879e-03  6.59766560e-03 -6.36112541e-02\n",
      "  3.22592817e-02  8.33294243e-02 -6.51409477e-02  7.93057978e-02\n",
      "  1.65968668e-02 -6.69790432e-02  1.87119711e-02 -7.05895051e-02\n",
      " -6.46949187e-02  8.36463347e-02  6.39554560e-02 -3.75131443e-02\n",
      " -8.03205073e-02 -1.81551427e-01  1.65722184e-02 -1.39845625e-01\n",
      "  1.37988746e-01 -1.53360218e-01 -4.14100057e-03 -3.17752548e-02\n",
      " -5.20753115e-02  5.49316406e-04 -2.78379004e-02 -2.23183259e-02\n",
      "  9.17695835e-02  3.13251205e-02 -9.83135551e-02 -3.58238220e-02\n",
      " -6.83828490e-03  2.79728808e-02  5.52039519e-02 -7.19698370e-02\n",
      "  8.18551853e-02 -9.51772854e-02  4.98422459e-02 -2.53671501e-02\n",
      " -1.75816454e-02 -3.35270800e-02  1.60493124e-02 -6.22018650e-02\n",
      "  1.28338151e-02 -7.18988255e-02 -7.62798637e-02 -5.63307554e-02\n",
      "  8.41236636e-02 -3.42735881e-03 -2.28008861e-03  2.41675749e-02\n",
      "  5.96970767e-02 -4.39899154e-02  8.15664455e-02 -1.43568769e-01\n",
      " -4.07010578e-02  1.08454777e-02 -2.55995523e-03  1.70041602e-02\n",
      " -3.99146453e-02 -1.23643145e-01 -3.63112241e-02 -1.13196736e-02\n",
      "  1.80628859e-02  1.01136431e-01 -1.53057389e-02  2.44680550e-02\n",
      "  2.58363578e-02  6.02675229e-02 -1.05224609e-01  7.60721043e-02\n",
      " -1.22774560e-02 -7.25473240e-02 -7.81435594e-02 -2.52767699e-03\n",
      "  5.52790724e-02 -1.85218221e-03 -1.52212288e-02 -7.62229338e-02\n",
      " -1.36777386e-01  1.50862476e-02  1.27528259e-03  8.76042321e-02\n",
      "  1.13196738e-01 -2.15172395e-02  1.03027344e-01 -8.17786008e-02\n",
      " -4.76215072e-02 -7.17726499e-02  5.64340455e-03  3.23181152e-02\n",
      "  8.38435218e-02 -1.31856482e-02  1.15300402e-01  1.04563199e-01\n",
      " -5.29386066e-02 -1.29664494e-02 -1.79337729e-02  2.46089064e-02\n",
      "  4.95276824e-02  7.59512112e-02 -9.96569097e-02  3.05257943e-02\n",
      " -1.29840553e-01  1.75010972e-02 -7.93479010e-03  9.64760408e-02\n",
      " -3.07182893e-02  1.95541382e-02  6.79391697e-02  6.43216670e-02] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_jd</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "      <td>[silver, stream, healthcare, group, offer, gre...</td>\n",
       "      <td>[-0.04270588, 0.0259989, 0.015020199, 0.031403...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical nurse manager (cnm)</td>\n",
       "      <td>sj_358f1f68cde928c4</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>231</td>\n",
       "      <td>[create, a, better, future, for, yourself, rec...</td>\n",
       "      <td>[-0.067376204, 0.035147008, 0.023164311, 0.027...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "1   clinical nurse manager (cnm)  sj_358f1f68cde928c4   \n",
       "\n",
       "                                                link              date  \\\n",
       "0  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "1  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...           unknown   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "1  create a better future for yourself  recruitne...  registered_nurse   \n",
       "\n",
       "   word_count                                       processed_jd  \\\n",
       "0         502  [silver, stream, healthcare, group, offer, gre...   \n",
       "1         231  [create, a, better, future, for, yourself, rec...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [-0.04270588, 0.0259989, 0.015020199, 0.031403...  \n",
       "1  [-0.067376204, 0.035147008, 0.023164311, 0.027...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to embed the input text.\n",
    "df_word2vec_js['vectors'] = df_word2vec_js['processed_ci'].apply(lambda x: embed_tokens(x, word2vec))\n",
    "df_word2vec_ja['vectors'] = df_word2vec_ja['processed_jd'].apply(lambda x: embed_tokens(x, word2vec))\n",
    "\n",
    "print('The shape of the first random vector is:', df_word2vec_js.iat[0, -1].shape, '\\n')\n",
    "print('The shape of the second random vector is:', df_word2vec_js.iat[1, -1].shape, '\\n')\n",
    "print(df_word2vec_js.iat[0, -1], '\\n')\n",
    "\n",
    "df_word2vec_ja.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each text column underwent preprocessing and tokenization, followed by the extraction of its embeddings. As demonstrated by the output of the preceding cells, each piece of text now possesses a vector value with a fixed dimensionality of 300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*calculate cosine*\n",
    "\n",
    "Using the costum function for cosine computation, we can get the similarity score of job ads for each experiment's participant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the vector values for each user and assign it to a new variable.\n",
    "user1_vector = df_word2vec_js.iat[0, -1].copy()\n",
    "user2_vector = df_word2vec_js.iat[1, -1].copy()\n",
    "user3_vector = df_word2vec_js.iat[2, -1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity.\n",
    "df_word2vec_ja['cos_user1'] = df_word2vec_ja['vectors'].apply(lambda x: cos(x, user1_vector))\n",
    "df_word2vec_ja['cos_user2'] = df_word2vec_ja['vectors'].apply(lambda x: cos(x, user2_vector))\n",
    "df_word2vec_ja['cos_user3'] = df_word2vec_ja['vectors'].apply(lambda x: cos(x, user3_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cos_user1</th>\n",
       "      <th>cos_user2</th>\n",
       "      <th>cos_user3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "      <td>0.698632</td>\n",
       "      <td>0.601519</td>\n",
       "      <td>0.501146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical nurse manager (cnm)</td>\n",
       "      <td>sj_358f1f68cde928c4</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>231</td>\n",
       "      <td>0.779827</td>\n",
       "      <td>0.687005</td>\n",
       "      <td>0.570256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "1   clinical nurse manager (cnm)  sj_358f1f68cde928c4   \n",
       "\n",
       "                                                link              date  \\\n",
       "0  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "1  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...           unknown   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "1  create a better future for yourself  recruitne...  registered_nurse   \n",
       "\n",
       "   word_count  cos_user1  cos_user2  cos_user3  \n",
       "0         502   0.698632   0.601519   0.501146  \n",
       "1         231   0.779827   0.687005   0.570256  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns.\n",
    "df_word2vec_ja.drop(columns=['processed_jd', 'vectors'], inplace=True)\n",
    "# Save the DF to local drive.\n",
    "df_word2vec_ja.to_csv('cosine_word2vec.csv', index=False)\n",
    "\n",
    "df_word2vec_ja.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine similarity scores were calculated for each user, and the resulting DF, now including the cosine similarity results, has been saved locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculation of cosine similarity using pretrained Word2Vec model completed in: 0 minutes and 22 seconds.\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(f'The calculation of cosine similarity using pretrained Word2Vec model completed in: {int((end - start)) // 60} minutes and {int((end - start)) % 60} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. WITH TF-IDF AND BOW\n",
    "\n",
    "In this sub-section text of each DF is converted into numerical form using TF-IDF and BoW and then compared for cosine similarity with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the timer to track the execution duration.\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*initialize tools*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a TF-IDF vectorizer object.\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "# Initialize a bag-of-words (BoW) vectorizer object.\n",
    "bow_vectorizer = CountVectorizer()\n",
    "# Initialize a WordNet lemmatizer object.\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*load dataset*\n",
    "\n",
    "As for the datasets, dublicates of the primary DFs are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets.\n",
    "df_tfidf_js = df_jobseeker.copy()\n",
    "df_tfidf_ja = df_jobads.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*create custom function*\n",
    "\n",
    "The preprocessing and tokenization steps for TF-IDF and BoW tools are distinct from those used in transformers and neural network architecture. These two text representation methods uses whole words to create embeddings, without any set limit on the number of tokens, and their functionality is reliant on the specific vocabulary found within their individual corpora. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a costum function for preprocessing and tokenizing the text.\n",
    "def preprocess_text_tfidf(text):\n",
    "    # Lowercasing.\n",
    "    text = text.lower()\n",
    "    # Removing punctuation.\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Tokenization.\n",
    "    tokens = word_tokenize(text)\n",
    "    # Removing stopwords and lemmatization.\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    processed_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    # Re-joining tokens.\n",
    "    processed_text = ' '.join(processed_tokens)\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*preprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>data_collection</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>preferred_position</th>\n",
       "      <th>combined_info</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-17 15:30:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>registered nurse</td>\n",
       "      <td>bachelor's degree: critical care nursing. pati...</td>\n",
       "      <td>27</td>\n",
       "      <td>bachelor degree critical care nursing patient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>voice call</td>\n",
       "      <td>2023-12-27 11:50:00</td>\n",
       "      <td>dublin, ireland</td>\n",
       "      <td>electrician</td>\n",
       "      <td>high school diploma, vocational electrician ce...</td>\n",
       "      <td>33</td>\n",
       "      <td>high school diploma vocational electrician cer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant data_collection                 date         location  \\\n",
       "0      user_1      voice call  2023-12-17 15:30:00  dublin, ireland   \n",
       "1      user_2      voice call  2023-12-27 11:50:00  dublin, ireland   \n",
       "\n",
       "  preferred_position                                      combined_info  \\\n",
       "0   registered nurse  bachelor's degree: critical care nursing. pati...   \n",
       "1        electrician  high school diploma, vocational electrician ce...   \n",
       "\n",
       "   word_count                                       processed_ci  \n",
       "0          27  bachelor degree critical care nursing patient ...  \n",
       "1          33  high school diploma vocational electrician cer...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to preprocess the input text.\n",
    "df_tfidf_js['processed_ci'] = df_tfidf_js['combined_info'].apply(preprocess_text_tfidf)\n",
    "df_tfidf_ja['processed_jd'] = df_tfidf_ja['job_description'].apply(preprocess_text_tfidf)\n",
    "\n",
    "df_tfidf_js.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom function has been applied to the text columns of both DFs, and now we need to merge the text into asingle one DF to create a unified corpus for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_jd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>bachelor degree critical care nursing patient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>high school diploma vocational electrician cer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>degree master science data analytics bachelor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "\n",
       "                                                link              date  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "\n",
       "  word_count                                       processed_jd  \n",
       "0             bachelor degree critical care nursing patient ...  \n",
       "1             high school diploma vocational electrician cer...  \n",
       "2             degree master science data analytics bachelor ...  \n",
       "3        502  silver stream healthcare group offer great emp...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with empty values, matching the columns of df_tfidf_ja, repeated three times.\n",
    "empty_rows = pd.DataFrame([[''] * len(df_tfidf_ja.columns)] * 3, columns=df_tfidf_ja.columns)\n",
    "\n",
    "df_tfidf_ja = pd.concat([empty_rows, df_tfidf_ja], ignore_index=True)\n",
    "values_to_add = df_tfidf_js['processed_ci'].tolist()[:3]\n",
    "df_tfidf_ja['processed_jd'].iloc[:3] = values_to_add\n",
    "\n",
    "df_tfidf_ja.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*embedding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the newly created vectors are: (20162,)\n",
      "The vectors are stored as a: <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_jd</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>bachelor degree critical care nursing patient ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>high school diploma vocational electrician cer...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>degree master science data analytics bachelor ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>[0.0, 0.0, 0.04749643991878368, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "\n",
       "                                                link              date  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "\n",
       "  word_count                                       processed_jd  \\\n",
       "0             bachelor degree critical care nursing patient ...   \n",
       "1             high school diploma vocational electrician cer...   \n",
       "2             degree master science data analytics bachelor ...   \n",
       "3        502  silver stream healthcare group offer great emp...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.04749643991878368, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the column values into a TF-IDF matrix.\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_tfidf_ja['processed_jd'])\n",
    "# Transform the column values into a BoW matrix.\n",
    "bow_matrix = bow_vectorizer.fit_transform(df_tfidf_ja['processed_jd'])\n",
    "# Combine the TF-IDF matrix and the BoW matrix horizontally (side by side).\n",
    "combined_matrix = hstack([tfidf_matrix, bow_matrix])\n",
    "# Convert each row of the matrix to a list and store in a new DF column.\n",
    "df_tfidf_ja['vectors'] = list(combined_matrix.toarray())\n",
    "\n",
    "check_vector = df_tfidf_ja.iat[0, -1]\n",
    "print('The dimensions of the newly created vectors are:', check_vector.shape)\n",
    "print('The vectors are stored as a:', type(check_vector))\n",
    "df_tfidf_ja.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text is transformed into matrices by TF-IDF and BoW vectorizers, which are then integrated into a single matrix using horizontal stacking tool, allowing to learn more about the text from both frequency of words and the importance of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*normalization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20152</th>\n",
       "      <th>20153</th>\n",
       "      <th>20154</th>\n",
       "      <th>20155</th>\n",
       "      <th>20156</th>\n",
       "      <th>20157</th>\n",
       "      <th>20158</th>\n",
       "      <th>20159</th>\n",
       "      <th>20160</th>\n",
       "      <th>20161</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 20162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1         2      3      4      5      6      7      8      9      \\\n",
       "0    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2    0.0    0.0  0.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3    0.0    0.0  0.047496    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   ...  20152  20153  20154  20155  20156  20157  20158  20159  20160  20161  \n",
       "0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[4 rows x 20162 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vectors array.\n",
    "vectors_array = pd.DataFrame(df_tfidf_ja['vectors'].tolist())\n",
    "vectors_array.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_jd</th>\n",
       "      <th>vectors</th>\n",
       "      <th>normolized_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>bachelor degree critical care nursing patient ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>high school diploma vocational electrician cer...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>degree master science data analytics bachelor ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>[0.0, 0.0, 0.04749643991878368, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0016647493576457985, 0.0, 0.0, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "2                                                       \n",
       "3  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "\n",
       "                                                link              date  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "\n",
       "  word_count                                       processed_jd  \\\n",
       "0             bachelor degree critical care nursing patient ...   \n",
       "1             high school diploma vocational electrician cer...   \n",
       "2             degree master science data analytics bachelor ...   \n",
       "3        502  silver stream healthcare group offer great emp...   \n",
       "\n",
       "                                             vectors  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.04749643991878368, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                      normolized_vec  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0016647493576457985, 0.0, 0.0, 0....  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the vectors using L2 normalization along the rows.\n",
    "normalized_vectors = normalize(vectors_array, norm='l2', axis=1)\n",
    "# Convert the normalized vectors to a list and assign them to a new column.\n",
    "df_tfidf_ja['normolized_vec'] = normalized_vectors.tolist()\n",
    "\n",
    "df_tfidf_ja.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF and BoW vectorizations produce feature vectors that are on different scales. While BoW counts are integer frequencies of words in documents, TF-IDF weights are floating-point numbers that reflect how important a word is to a document in a collection. Normalization ensures that these features contribute equally to the analysis, preventing features with larger scales from dominating the model's behavior in a future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*calculate cosine*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the vector's collection is: (1169, 20162)\n",
      "The final shape of the single vector is: (1, 20162)\n"
     ]
    }
   ],
   "source": [
    "# Convert the normalized vectors to a NumPy array.\n",
    "vectors_tf = np.array(df_tfidf_ja['normolized_vec'].tolist()).copy()\n",
    "\n",
    "# Reshape vector to a row vector.\n",
    "user1_vector_tf = vectors_tf[0].reshape(1, -1).copy()\n",
    "user2_vector_tf = vectors_tf[1].reshape(1, -1).copy()\n",
    "user3_vector_tf = vectors_tf[2].reshape(1, -1).copy()\n",
    "\n",
    "print(\"The shape of the vector's collection is:\", vectors_tf.shape)\n",
    "print('The final shape of the single vector is:', user1_vector_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarities between the vector for user1, user2 and user3 and all vectors in vectors_tf.\n",
    "cos_sim = cos(user1_vector_tf, vectors_tf).flatten()\n",
    "df_tfidf_ja['cos_user1'] = cos_sim\n",
    "\n",
    "cos_sim = cos(user2_vector_tf, vectors_tf).flatten()\n",
    "df_tfidf_ja['cos_user2'] = cos_sim\n",
    "\n",
    "cos_sim = cos(user3_vector_tf, vectors_tf).flatten()\n",
    "df_tfidf_ja['cos_user3'] = cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>job_description</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cos_user1</th>\n",
       "      <th>cos_user2</th>\n",
       "      <th>cos_user3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>assistant director of nursing</td>\n",
       "      <td>sj_3c7e64c7996bb9d6</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>January 10, 2024</td>\n",
       "      <td>silver stream healthcare group offer great emp...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>502</td>\n",
       "      <td>0.301457</td>\n",
       "      <td>0.022477</td>\n",
       "      <td>0.033491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical nurse manager (cnm)</td>\n",
       "      <td>sj_358f1f68cde928c4</td>\n",
       "      <td>https://ie.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>create a better future for yourself  recruitne...</td>\n",
       "      <td>registered_nurse</td>\n",
       "      <td>231</td>\n",
       "      <td>0.301988</td>\n",
       "      <td>0.037650</td>\n",
       "      <td>0.005109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title                   id  \\\n",
       "0  assistant director of nursing  sj_3c7e64c7996bb9d6   \n",
       "1   clinical nurse manager (cnm)  sj_358f1f68cde928c4   \n",
       "\n",
       "                                                link              date  \\\n",
       "0  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...  January 10, 2024   \n",
       "1  https://ie.indeed.com/pagead/clk?mo=r&ad=-6NYl...           unknown   \n",
       "\n",
       "                                     job_description             label  \\\n",
       "0  silver stream healthcare group offer great emp...  registered_nurse   \n",
       "1  create a better future for yourself  recruitne...  registered_nurse   \n",
       "\n",
       "  word_count  cos_user1  cos_user2  cos_user3  \n",
       "0        502   0.301457   0.022477   0.033491  \n",
       "1        231   0.301988   0.037650   0.005109  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing first three rows.\n",
    "df_tfidf_ja = df_tfidf_ja.iloc[3:].reset_index(drop=True)\n",
    "# Removing unnecessary columns.\n",
    "df_tfidf_ja.drop(columns=['processed_jd', 'vectors', 'normolized_vec'], inplace=True)\n",
    "# Save the DF to local drive.\n",
    "df_tfidf_ja.to_csv('cosine_tfidf.csv', index=False)\n",
    "\n",
    "df_tfidf_ja.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculation of cosine similarity using TF-IDF and BoW completed in: 0 minutes and 16 seconds.\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(f'The calculation of cosine similarity using TF-IDF and BoW completed in: {int((end - start)) // 60} minutes and {int((end - start)) % 60} seconds.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
